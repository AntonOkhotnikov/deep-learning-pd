{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout, Flatten, Convolution1D as Conv1D, Convolution2D as Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import MaxPooling1D, AveragePooling1D, BatchNormalization as BatchNorm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mainfs/lyceum/ao2u17/Dissertation\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "filename = '/encoding_A_freq100_chunks200.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (14806,)\n",
      "Train shape (14806, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "h5f = h5py.File(path + filename,'r')\n",
    "X_train = h5f['train'][:]\n",
    "Y_train = h5f['target'][:]\n",
    "h5f.close()\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_17 (Conv1D)           (None, 451, 4)            204       \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 451, 4)            16        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 451, 4)            0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 451, 4)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 402, 8)            1608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 402, 8)            32        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 402, 8)            0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 402, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 353, 16)           6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 353, 16)           64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 353, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 304, 32)           25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 304, 32)           128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 304, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 304, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 255, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 255, 64)           256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 255, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 255, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 206, 128)          409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 206, 128)          512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 206, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 645,621\n",
      "Trainable params: 645,117\n",
      "Non-trainable params: 504\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/80\n",
      "11326/11326 [==============================] - 7s 640us/step - loss: 0.7955 - binary_accuracy: 0.5573 - val_loss: 0.6786 - val_binary_accuracy: 0.6083\n",
      "Epoch 2/80\n",
      "11326/11326 [==============================] - 3s 305us/step - loss: 0.6767 - binary_accuracy: 0.6089 - val_loss: 0.7424 - val_binary_accuracy: 0.6168\n",
      "Epoch 3/80\n",
      "11326/11326 [==============================] - 3s 304us/step - loss: 0.6644 - binary_accuracy: 0.6188 - val_loss: 0.7344 - val_binary_accuracy: 0.6463\n",
      "Epoch 4/80\n",
      "11326/11326 [==============================] - 3s 304us/step - loss: 0.6538 - binary_accuracy: 0.6345 - val_loss: 0.6501 - val_binary_accuracy: 0.6453\n",
      "Epoch 5/80\n",
      "11326/11326 [==============================] - 3s 304us/step - loss: 0.6420 - binary_accuracy: 0.6422 - val_loss: 0.6885 - val_binary_accuracy: 0.6468\n",
      "Epoch 6/80\n",
      "11326/11326 [==============================] - 3s 304us/step - loss: 0.6290 - binary_accuracy: 0.6485 - val_loss: 0.6391 - val_binary_accuracy: 0.6533\n",
      "Epoch 7/80\n",
      "11326/11326 [==============================] - 3s 307us/step - loss: 0.6164 - binary_accuracy: 0.6576 - val_loss: 0.6384 - val_binary_accuracy: 0.6703\n",
      "Epoch 8/80\n",
      "11326/11326 [==============================] - 3s 305us/step - loss: 0.6201 - binary_accuracy: 0.6588 - val_loss: 1.0245 - val_binary_accuracy: 0.6183\n",
      "Epoch 9/80\n",
      "11326/11326 [==============================] - 3s 303us/step - loss: 0.6131 - binary_accuracy: 0.6579 - val_loss: 0.6424 - val_binary_accuracy: 0.6218\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "### Alternative model - 2 conv layers\n",
    "np.random.seed(15)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 80\n",
    "nb_classes = 1\n",
    "dropout = 0.1\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=50))\n",
    "model.add(BatchNorm())\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=50))\n",
    "model.add(BatchNorm())\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(MaxPooling1D(pool_size=pool_size, strides=strides))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# sgd gives better performance but it is slow, so use adam to check the ideas\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481/1481 [==============================] - 0s 126us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6488692943990271, 0.626603646345995]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_pred = model.predict(X_test)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6151249155975692\n",
      "AUC is 0.6946108440200192\n",
      "F1-score is 0.677601809954751\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_proba(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7153888329922354"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.legend(['Validation loss', 'Training loss'], loc='upper right')\n",
    "plt.savefig('graphs/loss.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11325/11325 [==============================] - 5s 401us/step - loss: 3.7879 - binary_accuracy: 0.5559 - val_loss: 0.9091 - val_binary_accuracy: 0.4672\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6950 - binary_accuracy: 0.6088 - val_loss: 0.8072 - val_binary_accuracy: 0.4687\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 2s 212us/step - loss: 0.6633 - binary_accuracy: 0.6247 - val_loss: 0.7946 - val_binary_accuracy: 0.4492\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6452 - binary_accuracy: 0.6273 - val_loss: 0.8242 - val_binary_accuracy: 0.4317\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 2s 212us/step - loss: 0.6296 - binary_accuracy: 0.6484 - val_loss: 0.8017 - val_binary_accuracy: 0.3862\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6249 - binary_accuracy: 0.6479 - val_loss: 0.7691 - val_binary_accuracy: 0.4812\n",
      "Epoch 7/30\n",
      "11325/11325 [==============================] - 2s 212us/step - loss: 0.6102 - binary_accuracy: 0.6588 - val_loss: 0.7689 - val_binary_accuracy: 0.4537\n",
      "Epoch 8/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6060 - binary_accuracy: 0.6687 - val_loss: 0.7808 - val_binary_accuracy: 0.5228\n",
      "Epoch 9/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6050 - binary_accuracy: 0.6645 - val_loss: 0.7640 - val_binary_accuracy: 0.4932\n",
      "Epoch 00009: early stopping\n",
      "Accuracy is 0.6707152496626181\n",
      "AUC is 0.7288414641919864\n",
      "F1-score is 0.6611111111111111\n",
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11325/11325 [==============================] - 5s 411us/step - loss: 3.1664 - binary_accuracy: 0.5680 - val_loss: 0.9324 - val_binary_accuracy: 0.4907\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 2s 213us/step - loss: 0.7084 - binary_accuracy: 0.6082 - val_loss: 0.8123 - val_binary_accuracy: 0.4662\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 2s 211us/step - loss: 0.6459 - binary_accuracy: 0.6276 - val_loss: 0.7854 - val_binary_accuracy: 0.4347\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 2s 213us/step - loss: 0.6282 - binary_accuracy: 0.6445 - val_loss: 0.7732 - val_binary_accuracy: 0.4857\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 2s 214us/step - loss: 0.6158 - binary_accuracy: 0.6531 - val_loss: 0.8068 - val_binary_accuracy: 0.3967\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 2s 214us/step - loss: 0.6103 - binary_accuracy: 0.6585 - val_loss: 0.7701 - val_binary_accuracy: 0.3782\n",
      "Epoch 7/30\n",
      "11325/11325 [==============================] - 2s 213us/step - loss: 0.6016 - binary_accuracy: 0.6671 - val_loss: 0.7906 - val_binary_accuracy: 0.4242\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.6383265856950068\n",
      "AUC is 0.7147433620904748\n",
      "F1-score is 0.6624685138539043\n",
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 5s 415us/step - loss: 2.9219 - binary_accuracy: 0.5560 - val_loss: 0.8833 - val_binary_accuracy: 0.4602\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 2s 213us/step - loss: 0.6890 - binary_accuracy: 0.6138 - val_loss: 0.7634 - val_binary_accuracy: 0.5953\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 2s 213us/step - loss: 0.6546 - binary_accuracy: 0.6298 - val_loss: 0.8344 - val_binary_accuracy: 0.4382\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 2s 214us/step - loss: 0.6267 - binary_accuracy: 0.6445 - val_loss: 0.8007 - val_binary_accuracy: 0.3932\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 2s 211us/step - loss: 0.6239 - binary_accuracy: 0.6474 - val_loss: 0.7834 - val_binary_accuracy: 0.4222\n",
      "Epoch 00005: early stopping\n",
      "Accuracy is 0.6205266711681297\n",
      "AUC is 0.682789874895138\n",
      "F1-score is 0.6589805825242719\n",
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 5s 426us/step - loss: 3.4312 - binary_accuracy: 0.5573 - val_loss: 0.9924 - val_binary_accuracy: 0.4912\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 2s 213us/step - loss: 0.6978 - binary_accuracy: 0.6087 - val_loss: 0.8180 - val_binary_accuracy: 0.4322\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 2s 214us/step - loss: 0.6401 - binary_accuracy: 0.6325 - val_loss: 0.7530 - val_binary_accuracy: 0.4807\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 2s 214us/step - loss: 0.6247 - binary_accuracy: 0.6516 - val_loss: 0.7462 - val_binary_accuracy: 0.4652\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 2s 214us/step - loss: 0.6202 - binary_accuracy: 0.6520 - val_loss: 0.7664 - val_binary_accuracy: 0.4492\n",
      "Epoch 6/30\n",
      "11326/11326 [==============================] - 2s 214us/step - loss: 0.6086 - binary_accuracy: 0.6646 - val_loss: 0.8009 - val_binary_accuracy: 0.3927\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.611748818365969\n",
      "AUC is 0.6965568807674071\n",
      "F1-score is 0.6693502012650948\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 5s 435us/step - loss: 2.9951 - binary_accuracy: 0.5446 - val_loss: 1.2837 - val_binary_accuracy: 0.4602\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 213us/step - loss: 0.7062 - binary_accuracy: 0.6086 - val_loss: 0.7891 - val_binary_accuracy: 0.4442\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.6560 - binary_accuracy: 0.6298 - val_loss: 0.7905 - val_binary_accuracy: 0.4592\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6331 - binary_accuracy: 0.6395 - val_loss: 0.7716 - val_binary_accuracy: 0.4692\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 212us/step - loss: 0.6347 - binary_accuracy: 0.6356 - val_loss: 0.7558 - val_binary_accuracy: 0.4727\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 213us/step - loss: 0.6118 - binary_accuracy: 0.6575 - val_loss: 0.7521 - val_binary_accuracy: 0.4562\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.6063 - binary_accuracy: 0.6605 - val_loss: 0.7719 - val_binary_accuracy: 0.4067\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 2s 213us/step - loss: 0.5997 - binary_accuracy: 0.6694 - val_loss: 0.7337 - val_binary_accuracy: 0.5648\n",
      "Epoch 9/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.5942 - binary_accuracy: 0.6726 - val_loss: 0.7626 - val_binary_accuracy: 0.4562\n",
      "Epoch 10/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.5982 - binary_accuracy: 0.6744 - val_loss: 0.8016 - val_binary_accuracy: 0.3887\n",
      "Epoch 11/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.5949 - binary_accuracy: 0.6778 - val_loss: 0.7206 - val_binary_accuracy: 0.5638\n",
      "Epoch 12/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.5900 - binary_accuracy: 0.6805 - val_loss: 0.7712 - val_binary_accuracy: 0.4542\n",
      "Epoch 13/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.5869 - binary_accuracy: 0.6845 - val_loss: 0.8192 - val_binary_accuracy: 0.4192\n",
      "Epoch 14/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.5860 - binary_accuracy: 0.6828 - val_loss: 0.7269 - val_binary_accuracy: 0.6218\n",
      "Epoch 00014: early stopping\n",
      "Accuracy is 0.6222972972972973\n",
      "AUC is 0.6819357195032871\n",
      "F1-score is 0.4847926267281105\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 5s 444us/step - loss: 1.5516 - binary_accuracy: 0.5662 - val_loss: 0.9860 - val_binary_accuracy: 0.3992\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.7207 - binary_accuracy: 0.5982 - val_loss: 0.7910 - val_binary_accuracy: 0.5378\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.6959 - binary_accuracy: 0.6174 - val_loss: 0.9225 - val_binary_accuracy: 0.3717\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.6647 - binary_accuracy: 0.6258 - val_loss: 0.7079 - val_binary_accuracy: 0.6263\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6282 - binary_accuracy: 0.6450 - val_loss: 0.7949 - val_binary_accuracy: 0.4207\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6084 - binary_accuracy: 0.6593 - val_loss: 0.7516 - val_binary_accuracy: 0.5463\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6049 - binary_accuracy: 0.6676 - val_loss: 0.7810 - val_binary_accuracy: 0.5068\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.6385135135135135\n",
      "AUC is 0.715968772826881\n",
      "F1-score is 0.676737160120846\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 5s 452us/step - loss: 4.1226 - binary_accuracy: 0.5581 - val_loss: 1.0282 - val_binary_accuracy: 0.5553\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.7719 - binary_accuracy: 0.5981 - val_loss: 0.9592 - val_binary_accuracy: 0.3587\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6949 - binary_accuracy: 0.6162 - val_loss: 0.7696 - val_binary_accuracy: 0.5143\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 214us/step - loss: 0.6463 - binary_accuracy: 0.6375 - val_loss: 0.7954 - val_binary_accuracy: 0.3932\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6116 - binary_accuracy: 0.6641 - val_loss: 0.7472 - val_binary_accuracy: 0.5473\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 217us/step - loss: 0.6160 - binary_accuracy: 0.6571 - val_loss: 0.7695 - val_binary_accuracy: 0.4302\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6050 - binary_accuracy: 0.6638 - val_loss: 0.7399 - val_binary_accuracy: 0.5053\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6058 - binary_accuracy: 0.6688 - val_loss: 0.7676 - val_binary_accuracy: 0.4522\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6405405405405405\n",
      "AUC is 0.706490138787436\n",
      "F1-score is 0.6522875816993463\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 5s 462us/step - loss: 2.8809 - binary_accuracy: 0.5494 - val_loss: 0.8549 - val_binary_accuracy: 0.5003\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.7034 - binary_accuracy: 0.6087 - val_loss: 0.8523 - val_binary_accuracy: 0.4207\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6607 - binary_accuracy: 0.6251 - val_loss: 0.8275 - val_binary_accuracy: 0.4102\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6363 - binary_accuracy: 0.6369 - val_loss: 0.8339 - val_binary_accuracy: 0.4077\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6236 - binary_accuracy: 0.6490 - val_loss: 0.8086 - val_binary_accuracy: 0.4387\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6179 - binary_accuracy: 0.6520 - val_loss: 0.7649 - val_binary_accuracy: 0.4327\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6074 - binary_accuracy: 0.6624 - val_loss: 0.7614 - val_binary_accuracy: 0.4647\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.5990 - binary_accuracy: 0.6714 - val_loss: 0.7635 - val_binary_accuracy: 0.4082\n",
      "Epoch 9/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6003 - binary_accuracy: 0.6690 - val_loss: 0.7241 - val_binary_accuracy: 0.5528\n",
      "Epoch 10/30\n",
      "11327/11327 [==============================] - 2s 217us/step - loss: 0.5942 - binary_accuracy: 0.6744 - val_loss: 0.8499 - val_binary_accuracy: 0.3657\n",
      "Epoch 11/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.5910 - binary_accuracy: 0.6818 - val_loss: 0.8037 - val_binary_accuracy: 0.4237\n",
      "Epoch 12/30\n",
      "11327/11327 [==============================] - 2s 217us/step - loss: 0.5897 - binary_accuracy: 0.6772 - val_loss: 0.8325 - val_binary_accuracy: 0.4012\n",
      "Epoch 00012: early stopping\n",
      "Accuracy is 0.6263513513513513\n",
      "AUC is 0.7389043097151204\n",
      "F1-score is 0.6996197718631179\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 6s 496us/step - loss: 4.5847 - binary_accuracy: 0.5208 - val_loss: 1.1896 - val_binary_accuracy: 0.4967\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 218us/step - loss: 0.7060 - binary_accuracy: 0.6178 - val_loss: 0.7834 - val_binary_accuracy: 0.4622\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6320 - binary_accuracy: 0.6402 - val_loss: 0.7604 - val_binary_accuracy: 0.4612\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6296 - binary_accuracy: 0.6432 - val_loss: 0.7682 - val_binary_accuracy: 0.4577\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 219us/step - loss: 0.6182 - binary_accuracy: 0.6504 - val_loss: 0.7418 - val_binary_accuracy: 0.4667\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6093 - binary_accuracy: 0.6641 - val_loss: 0.7771 - val_binary_accuracy: 0.3772\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6082 - binary_accuracy: 0.6607 - val_loss: 0.7971 - val_binary_accuracy: 0.4037\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 2s 218us/step - loss: 0.5984 - binary_accuracy: 0.6699 - val_loss: 0.7533 - val_binary_accuracy: 0.4977\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6432432432432432\n",
      "AUC is 0.6935052958363769\n",
      "F1-score is 0.6071428571428572\n",
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 5s 476us/step - loss: 1.0274 - binary_accuracy: 0.5784 - val_loss: 0.8845 - val_binary_accuracy: 0.5903\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.7447 - binary_accuracy: 0.6038 - val_loss: 0.8225 - val_binary_accuracy: 0.4292\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6574 - binary_accuracy: 0.6309 - val_loss: 0.7434 - val_binary_accuracy: 0.5683\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6511 - binary_accuracy: 0.6324 - val_loss: 0.9521 - val_binary_accuracy: 0.3682\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6521 - binary_accuracy: 0.6326 - val_loss: 0.7118 - val_binary_accuracy: 0.6073\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 2s 215us/step - loss: 0.6187 - binary_accuracy: 0.6564 - val_loss: 0.7845 - val_binary_accuracy: 0.4382\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 2s 217us/step - loss: 0.6043 - binary_accuracy: 0.6650 - val_loss: 0.7582 - val_binary_accuracy: 0.4612\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 2s 216us/step - loss: 0.6078 - binary_accuracy: 0.6584 - val_loss: 0.7259 - val_binary_accuracy: 0.5953\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6506756756756756\n",
      "AUC is 0.7011504747991235\n",
      "F1-score is 0.584070796460177\n",
      "Accuracy:  63.62938946513346\n",
      "AUC:  0.7060886293413231\n",
      "f1-score:  0.6356561202768838\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "#     extend_x = np.flip(X_train, axis=1)\n",
    "#     extend_y = Y_train\n",
    "\n",
    "#     X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "#     Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=10))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Conv1D(filters=128, kernel_size=10))\n",
    "    model.add(BatchNorm())\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size, strides=strides))  # was no strides before (default strides=pool_size)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    # sgd gives better performance but it is slow, so use adam to check the ideas\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "#     print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict_proba(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7288414641919864,\n",
       " 0.7147433620904748,\n",
       " 0.682789874895138,\n",
       " 0.6965568807674071,\n",
       " 0.6819357195032871,\n",
       " 0.715968772826881,\n",
       " 0.706490138787436,\n",
       " 0.7389043097151204,\n",
       " 0.6935052958363769,\n",
       " 0.7011504747991235]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.75807307054345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(acc_list)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7640082530309672"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(f1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8678913524149543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(AUC_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
