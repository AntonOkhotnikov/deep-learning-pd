{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers import Dropout, Flatten, Convolution1D as Conv1D, Convolution2D as Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Bidirectional, Input\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.layers import MaxPooling1D, AveragePooling1D, BatchNormalization as BatchNorm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mainfs/lyceum/ao2u17/Dissertation\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "filename = '/encoding_A_freq100_chunks200.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (14806,)\n",
      "Train shape (14806, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "# h5f = h5py.File(path + filename,'r')\n",
    "# X_train = h5f['train'][:]\n",
    "# Y_train = h5f['target'][:]\n",
    "# X_test = h5f['test'][:]\n",
    "# Y_test = h5f['target_test'][:]\n",
    "# h5f.close()\n",
    "\n",
    "# print('Target shape', Y_train.shape)\n",
    "# print('Train shape', X_train.shape)\n",
    "# print('Target test shape', Y_test.shape)\n",
    "# print('Test shape', X_test.shape)\n",
    "\n",
    "h5f = h5py.File(path + filename,'r')\n",
    "X_train = h5f['train'][:]\n",
    "Y_train = h5f['target'][:]\n",
    "h5f.close()\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend train set by flipping the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (29612,)\n",
      "Train shape (29612, 500, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dbf7d3374997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Target test shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test shape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "extend_x = np.flip(X_train, axis=1)\n",
    "extend_y = Y_train\n",
    "\n",
    "X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)\n",
    "# print('Target test shape', Y_test.shape)\n",
    "# print('Test shape', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model - Inception with different kernel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /lyceum/ao2u17/.conda/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 32)      992         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 32)      1312        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 500, 32)      1632        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 500, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 500, 32)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 500, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 64)      61504       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 500, 64)      81984       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 500, 64)      102464      leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 500, 64)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 500, 64)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 500, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 192)     0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 192)     768         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 500, 192)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 17, 192)      0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3264)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          417920      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 668,705\n",
      "Trainable params: 668,321\n",
      "Non-trainable params: 384\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 22596 samples, validate on 3988 samples\n",
      "Epoch 1/30\n",
      "22596/22596 [==============================] - 11s 486us/step - loss: 1.3299 - binary_accuracy: 0.6007 - val_loss: 0.6794 - val_binary_accuracy: 0.6021\n",
      "Epoch 2/30\n",
      "22596/22596 [==============================] - 8s 341us/step - loss: 0.6298 - binary_accuracy: 0.6459 - val_loss: 0.6268 - val_binary_accuracy: 0.6647\n",
      "Epoch 3/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.6052 - binary_accuracy: 0.6567 - val_loss: 0.6492 - val_binary_accuracy: 0.6399\n",
      "Epoch 4/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5964 - binary_accuracy: 0.6648 - val_loss: 0.6166 - val_binary_accuracy: 0.6652\n",
      "Epoch 5/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5929 - binary_accuracy: 0.6685 - val_loss: 0.6875 - val_binary_accuracy: 0.5840\n",
      "Epoch 6/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5865 - binary_accuracy: 0.6730 - val_loss: 0.6633 - val_binary_accuracy: 0.6254\n",
      "Epoch 7/30\n",
      "22596/22596 [==============================] - 8s 342us/step - loss: 0.5815 - binary_accuracy: 0.6771 - val_loss: 0.6239 - val_binary_accuracy: 0.6527\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "### Alternative model - 2 conv layers\n",
    "np.random.seed(14)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "# sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(filters=128, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size, strides=strides))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "\n",
    "tower_1 = Conv1D(filters=32, kernel_size=30, padding='same')(inp)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Conv1D(filters=64, kernel_size=30, padding='same')(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "\n",
    "tower_2 = Conv1D(filters=32, kernel_size=40, padding='same')(inp)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Conv1D(filters=64, kernel_size=40, padding='same')(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "\n",
    "tower_3 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "middle = BatchNorm()(middle)\n",
    "middle = LeakyReLU(alpha=0.01)(middle)\n",
    "middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "middle = Flatten()(middle)\n",
    "\n",
    "out = Dense(128, activation='linear')(middle)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping], \n",
    "                   validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6327608982826949\n",
      "AUC is 0.6974089475769089\n",
      "F1-score is 0.5716486902927581\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Y_pred)\n",
    "# Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception with dilated units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /lyceum/ao2u17/.conda/envs/keras_env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      816         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 500, 32)      1632        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 500, 32)      0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 32)      0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 500, 64)      3264        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 16)      12816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 500, 32)      51232       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 500, 64)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 500, 16)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 500, 32)      0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 500, 64)      0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 16)      0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 500, 32)      0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 500, 64)      204864      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 16)      12816       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 500, 32)      51232       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 500, 64)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 500, 16)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 500, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 500, 64)      204864      leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 16)      0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 500, 32)      0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 500, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 112)     0           dropout_3[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 112)     448         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 500, 112)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 17, 112)      0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1904)         0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 1904)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          243840      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 25170 samples, validate on 4442 samples\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "### Alternative model - 2 conv layers\n",
    "np.random.seed(14)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "# sgd = SGD(lr=0.005, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "print('Build model...')\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(input_shape=input_shape, filters=64, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Conv1D(filters=128, kernel_size=50))\n",
    "# model.add(BatchNorm())\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(MaxPooling1D(pool_size=pool_size, strides=strides))\n",
    "\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(dropout))\n",
    "\n",
    "# model.add(Dense(128))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "# model.add(Dense(nb_classes))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "inp = Input(shape=input_shape)\n",
    "\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Dropout(dropout)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "middle = BatchNorm()(middle)\n",
    "middle = LeakyReLU(alpha=0.01)(middle)\n",
    "middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "middle = Flatten()(middle)\n",
    "middle = Dropout(dropout)(middle)\n",
    "\n",
    "out = Dense(128, activation='linear')(middle)\n",
    "out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                    validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6056803170409512\n",
      "AUC is 0.669113810511841\n",
      "F1-score is 0.46264626462646263\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation - Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_72 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_640 (Conv1D)             (None, 500, 16)      816         input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_643 (Conv1D)             (None, 500, 32)      1632        input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_711 (LeakyReLU)     (None, 500, 16)      0           conv1d_640[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_714 (LeakyReLU)     (None, 500, 32)      0           conv1d_643[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_569 (Dropout)           (None, 500, 16)      0           leaky_re_lu_711[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_572 (Dropout)           (None, 500, 32)      0           leaky_re_lu_714[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_646 (Conv1D)             (None, 500, 64)      3264        input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_641 (Conv1D)             (None, 500, 16)      12816       dropout_569[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_644 (Conv1D)             (None, 500, 32)      51232       dropout_572[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_717 (LeakyReLU)     (None, 500, 64)      0           conv1d_646[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_712 (LeakyReLU)     (None, 500, 16)      0           conv1d_641[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_715 (LeakyReLU)     (None, 500, 32)      0           conv1d_644[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_575 (Dropout)           (None, 500, 64)      0           leaky_re_lu_717[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_570 (Dropout)           (None, 500, 16)      0           leaky_re_lu_712[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_573 (Dropout)           (None, 500, 32)      0           leaky_re_lu_715[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_647 (Conv1D)             (None, 500, 64)      204864      dropout_575[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_642 (Conv1D)             (None, 500, 16)      12816       dropout_570[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_645 (Conv1D)             (None, 500, 32)      51232       dropout_573[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_718 (LeakyReLU)     (None, 500, 64)      0           conv1d_647[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_713 (LeakyReLU)     (None, 500, 16)      0           conv1d_642[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_716 (LeakyReLU)     (None, 500, 32)      0           conv1d_645[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_648 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_718[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_571 (Dropout)           (None, 500, 16)      0           leaky_re_lu_713[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_574 (Dropout)           (None, 500, 32)      0           leaky_re_lu_716[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_719 (LeakyReLU)     (None, 500, 64)      0           conv1d_648[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 500, 112)     0           dropout_571[0][0]                \n",
      "                                                                 dropout_574[0][0]                \n",
      "                                                                 leaky_re_lu_719[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 500, 112)     448         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_720 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_720[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 1904)         0           max_pooling1d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_576 (Dropout)           (None, 1904)         0           flatten_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 128)          243840      dropout_576[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 1)            129         dense_143[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 20386 samples, validate on 3598 samples\n",
      "Epoch 1/30\n",
      "20386/20386 [==============================] - 29s 1ms/step - loss: 1.7353 - binary_accuracy: 0.5824 - val_loss: 0.6678 - val_binary_accuracy: 0.6209\n",
      "Epoch 2/30\n",
      "20386/20386 [==============================] - 12s 567us/step - loss: 0.6380 - binary_accuracy: 0.6450 - val_loss: 0.6542 - val_binary_accuracy: 0.6278\n",
      "Epoch 3/30\n",
      "20386/20386 [==============================] - 11s 563us/step - loss: 0.6092 - binary_accuracy: 0.6612 - val_loss: 0.6934 - val_binary_accuracy: 0.6151\n",
      "Epoch 4/30\n",
      "20386/20386 [==============================] - 12s 569us/step - loss: 0.5998 - binary_accuracy: 0.6627 - val_loss: 0.6356 - val_binary_accuracy: 0.6426\n",
      "Epoch 5/30\n",
      "20386/20386 [==============================] - 12s 564us/step - loss: 0.5907 - binary_accuracy: 0.6736 - val_loss: 0.6300 - val_binary_accuracy: 0.6590\n",
      "Epoch 6/30\n",
      "20386/20386 [==============================] - 12s 571us/step - loss: 0.5857 - binary_accuracy: 0.6755 - val_loss: 0.7176 - val_binary_accuracy: 0.5906\n",
      "Epoch 7/30\n",
      "20386/20386 [==============================] - 12s 566us/step - loss: 0.5820 - binary_accuracy: 0.6802 - val_loss: 0.7090 - val_binary_accuracy: 0.6165\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.636431784107946\n",
      "AUC is 0.7013434811829468\n",
      "F1-score is 0.6420664206642067\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_649 (Conv1D)             (None, 500, 16)      816         input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_652 (Conv1D)             (None, 500, 32)      1632        input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_721 (LeakyReLU)     (None, 500, 16)      0           conv1d_649[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_724 (LeakyReLU)     (None, 500, 32)      0           conv1d_652[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_577 (Dropout)           (None, 500, 16)      0           leaky_re_lu_721[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_580 (Dropout)           (None, 500, 32)      0           leaky_re_lu_724[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_655 (Conv1D)             (None, 500, 64)      3264        input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_650 (Conv1D)             (None, 500, 16)      12816       dropout_577[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_653 (Conv1D)             (None, 500, 32)      51232       dropout_580[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_727 (LeakyReLU)     (None, 500, 64)      0           conv1d_655[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_722 (LeakyReLU)     (None, 500, 16)      0           conv1d_650[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_725 (LeakyReLU)     (None, 500, 32)      0           conv1d_653[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_583 (Dropout)           (None, 500, 64)      0           leaky_re_lu_727[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_578 (Dropout)           (None, 500, 16)      0           leaky_re_lu_722[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_581 (Dropout)           (None, 500, 32)      0           leaky_re_lu_725[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_656 (Conv1D)             (None, 500, 64)      204864      dropout_583[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_651 (Conv1D)             (None, 500, 16)      12816       dropout_578[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_654 (Conv1D)             (None, 500, 32)      51232       dropout_581[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_728 (LeakyReLU)     (None, 500, 64)      0           conv1d_656[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_723 (LeakyReLU)     (None, 500, 16)      0           conv1d_651[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_726 (LeakyReLU)     (None, 500, 32)      0           conv1d_654[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_657 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_728[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_579 (Dropout)           (None, 500, 16)      0           leaky_re_lu_723[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_582 (Dropout)           (None, 500, 32)      0           leaky_re_lu_726[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_729 (LeakyReLU)     (None, 500, 64)      0           conv1d_657[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 500, 112)     0           dropout_579[0][0]                \n",
      "                                                                 dropout_582[0][0]                \n",
      "                                                                 leaky_re_lu_729[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 500, 112)     448         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_730 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_730[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 1904)         0           max_pooling1d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_584 (Dropout)           (None, 1904)         0           flatten_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 128)          243840      dropout_584[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 1)            129         dense_145[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 20386 samples, validate on 3598 samples\n",
      "Epoch 1/30\n",
      "20386/20386 [==============================] - 29s 1ms/step - loss: 1.6971 - binary_accuracy: 0.5777 - val_loss: 0.6697 - val_binary_accuracy: 0.6306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "20386/20386 [==============================] - 12s 595us/step - loss: 0.6494 - binary_accuracy: 0.6385 - val_loss: 0.6648 - val_binary_accuracy: 0.6354\n",
      "Epoch 3/30\n",
      "20386/20386 [==============================] - 12s 597us/step - loss: 0.6187 - binary_accuracy: 0.6537 - val_loss: 0.6660 - val_binary_accuracy: 0.6292\n",
      "Epoch 4/30\n",
      "20386/20386 [==============================] - 12s 592us/step - loss: 0.6049 - binary_accuracy: 0.6630 - val_loss: 0.7452 - val_binary_accuracy: 0.5798\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.6334332833583208\n",
      "AUC is 0.7208449748139425\n",
      "F1-score is 0.6597077244258872\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_74 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_658 (Conv1D)             (None, 500, 16)      816         input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_661 (Conv1D)             (None, 500, 32)      1632        input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_731 (LeakyReLU)     (None, 500, 16)      0           conv1d_658[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_734 (LeakyReLU)     (None, 500, 32)      0           conv1d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_585 (Dropout)           (None, 500, 16)      0           leaky_re_lu_731[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_588 (Dropout)           (None, 500, 32)      0           leaky_re_lu_734[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_664 (Conv1D)             (None, 500, 64)      3264        input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_659 (Conv1D)             (None, 500, 16)      12816       dropout_585[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_662 (Conv1D)             (None, 500, 32)      51232       dropout_588[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_737 (LeakyReLU)     (None, 500, 64)      0           conv1d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_732 (LeakyReLU)     (None, 500, 16)      0           conv1d_659[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_735 (LeakyReLU)     (None, 500, 32)      0           conv1d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_591 (Dropout)           (None, 500, 64)      0           leaky_re_lu_737[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_586 (Dropout)           (None, 500, 16)      0           leaky_re_lu_732[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_589 (Dropout)           (None, 500, 32)      0           leaky_re_lu_735[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_665 (Conv1D)             (None, 500, 64)      204864      dropout_591[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_660 (Conv1D)             (None, 500, 16)      12816       dropout_586[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_663 (Conv1D)             (None, 500, 32)      51232       dropout_589[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_738 (LeakyReLU)     (None, 500, 64)      0           conv1d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_733 (LeakyReLU)     (None, 500, 16)      0           conv1d_660[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_736 (LeakyReLU)     (None, 500, 32)      0           conv1d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_666 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_738[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_587 (Dropout)           (None, 500, 16)      0           leaky_re_lu_733[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_590 (Dropout)           (None, 500, 32)      0           leaky_re_lu_736[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_739 (LeakyReLU)     (None, 500, 64)      0           conv1d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 500, 112)     0           dropout_587[0][0]                \n",
      "                                                                 dropout_590[0][0]                \n",
      "                                                                 leaky_re_lu_739[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 500, 112)     448         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_740 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_740[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_74 (Flatten)            (None, 1904)         0           max_pooling1d_74[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_592 (Dropout)           (None, 1904)         0           flatten_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 128)          243840      dropout_592[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 1)            129         dense_147[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 20388 samples, validate on 3598 samples\n",
      "Epoch 1/30\n",
      "20388/20388 [==============================] - 30s 1ms/step - loss: 1.2109 - binary_accuracy: 0.5887 - val_loss: 0.6546 - val_binary_accuracy: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "20388/20388 [==============================] - 12s 595us/step - loss: 0.6388 - binary_accuracy: 0.6414 - val_loss: 0.6508 - val_binary_accuracy: 0.6473\n",
      "Epoch 3/30\n",
      "20388/20388 [==============================] - 12s 596us/step - loss: 0.6177 - binary_accuracy: 0.6532 - val_loss: 0.6469 - val_binary_accuracy: 0.6462\n",
      "Epoch 4/30\n",
      "20388/20388 [==============================] - 12s 595us/step - loss: 0.6005 - binary_accuracy: 0.6682 - val_loss: 0.6361 - val_binary_accuracy: 0.6467\n",
      "Epoch 5/30\n",
      "20388/20388 [==============================] - 12s 598us/step - loss: 0.5893 - binary_accuracy: 0.6738 - val_loss: 0.6310 - val_binary_accuracy: 0.6540\n",
      "Epoch 6/30\n",
      "20388/20388 [==============================] - 12s 603us/step - loss: 0.5878 - binary_accuracy: 0.6765 - val_loss: 0.6459 - val_binary_accuracy: 0.6456\n",
      "Epoch 7/30\n",
      "20388/20388 [==============================] - 12s 597us/step - loss: 0.5796 - binary_accuracy: 0.6840 - val_loss: 0.6416 - val_binary_accuracy: 0.6404\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.668417104276069\n",
      "AUC is 0.7386149267708488\n",
      "F1-score is 0.6400651465798045\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_667 (Conv1D)             (None, 500, 16)      816         input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_670 (Conv1D)             (None, 500, 32)      1632        input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_741 (LeakyReLU)     (None, 500, 16)      0           conv1d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_744 (LeakyReLU)     (None, 500, 32)      0           conv1d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_593 (Dropout)           (None, 500, 16)      0           leaky_re_lu_741[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_596 (Dropout)           (None, 500, 32)      0           leaky_re_lu_744[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_673 (Conv1D)             (None, 500, 64)      3264        input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_668 (Conv1D)             (None, 500, 16)      12816       dropout_593[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_671 (Conv1D)             (None, 500, 32)      51232       dropout_596[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_747 (LeakyReLU)     (None, 500, 64)      0           conv1d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_742 (LeakyReLU)     (None, 500, 16)      0           conv1d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_745 (LeakyReLU)     (None, 500, 32)      0           conv1d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_599 (Dropout)           (None, 500, 64)      0           leaky_re_lu_747[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_594 (Dropout)           (None, 500, 16)      0           leaky_re_lu_742[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_597 (Dropout)           (None, 500, 32)      0           leaky_re_lu_745[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_674 (Conv1D)             (None, 500, 64)      204864      dropout_599[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_669 (Conv1D)             (None, 500, 16)      12816       dropout_594[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_672 (Conv1D)             (None, 500, 32)      51232       dropout_597[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_748 (LeakyReLU)     (None, 500, 64)      0           conv1d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_743 (LeakyReLU)     (None, 500, 16)      0           conv1d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_746 (LeakyReLU)     (None, 500, 32)      0           conv1d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_675 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_748[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_595 (Dropout)           (None, 500, 16)      0           leaky_re_lu_743[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_598 (Dropout)           (None, 500, 32)      0           leaky_re_lu_746[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_749 (LeakyReLU)     (None, 500, 64)      0           conv1d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 500, 112)     0           dropout_595[0][0]                \n",
      "                                                                 dropout_598[0][0]                \n",
      "                                                                 leaky_re_lu_749[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 500, 112)     448         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_750 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_750[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 1904)         0           max_pooling1d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_600 (Dropout)           (None, 1904)         0           flatten_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 128)          243840      dropout_600[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 1)            129         dense_149[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20388 samples, validate on 3598 samples\n",
      "Epoch 1/30\n",
      "20388/20388 [==============================] - 30s 1ms/step - loss: 1.1521 - binary_accuracy: 0.5787 - val_loss: 0.6505 - val_binary_accuracy: 0.6568\n",
      "Epoch 2/30\n",
      "20388/20388 [==============================] - 12s 592us/step - loss: 0.6615 - binary_accuracy: 0.6268 - val_loss: 0.7493 - val_binary_accuracy: 0.6081\n",
      "Epoch 3/30\n",
      "20388/20388 [==============================] - 12s 597us/step - loss: 0.6213 - binary_accuracy: 0.6521 - val_loss: 0.7078 - val_binary_accuracy: 0.6106\n",
      "Epoch 4/30\n",
      "20388/20388 [==============================] - 12s 596us/step - loss: 0.6091 - binary_accuracy: 0.6635 - val_loss: 0.6547 - val_binary_accuracy: 0.6373\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.68192048012003\n",
      "AUC is 0.7445038741890316\n",
      "F1-score is 0.6280701754385966\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_76 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_676 (Conv1D)             (None, 500, 16)      816         input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_679 (Conv1D)             (None, 500, 32)      1632        input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_751 (LeakyReLU)     (None, 500, 16)      0           conv1d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_754 (LeakyReLU)     (None, 500, 32)      0           conv1d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_601 (Dropout)           (None, 500, 16)      0           leaky_re_lu_751[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_604 (Dropout)           (None, 500, 32)      0           leaky_re_lu_754[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_682 (Conv1D)             (None, 500, 64)      3264        input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_677 (Conv1D)             (None, 500, 16)      12816       dropout_601[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_680 (Conv1D)             (None, 500, 32)      51232       dropout_604[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_757 (LeakyReLU)     (None, 500, 64)      0           conv1d_682[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_752 (LeakyReLU)     (None, 500, 16)      0           conv1d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_755 (LeakyReLU)     (None, 500, 32)      0           conv1d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_607 (Dropout)           (None, 500, 64)      0           leaky_re_lu_757[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_602 (Dropout)           (None, 500, 16)      0           leaky_re_lu_752[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_605 (Dropout)           (None, 500, 32)      0           leaky_re_lu_755[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_683 (Conv1D)             (None, 500, 64)      204864      dropout_607[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_678 (Conv1D)             (None, 500, 16)      12816       dropout_602[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_681 (Conv1D)             (None, 500, 32)      51232       dropout_605[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_758 (LeakyReLU)     (None, 500, 64)      0           conv1d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_753 (LeakyReLU)     (None, 500, 16)      0           conv1d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_756 (LeakyReLU)     (None, 500, 32)      0           conv1d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_684 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_758[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_603 (Dropout)           (None, 500, 16)      0           leaky_re_lu_753[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_606 (Dropout)           (None, 500, 32)      0           leaky_re_lu_756[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_759 (LeakyReLU)     (None, 500, 64)      0           conv1d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 500, 112)     0           dropout_603[0][0]                \n",
      "                                                                 dropout_606[0][0]                \n",
      "                                                                 leaky_re_lu_759[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 500, 112)     448         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_760 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_760[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 1904)         0           max_pooling1d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_608 (Dropout)           (None, 1904)         0           flatten_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 128)          243840      dropout_608[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 1)            129         dense_151[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20389 samples, validate on 3599 samples\n",
      "Epoch 1/30\n",
      "20389/20389 [==============================] - 31s 2ms/step - loss: 1.4583 - binary_accuracy: 0.5807 - val_loss: 0.6903 - val_binary_accuracy: 0.6374\n",
      "Epoch 2/30\n",
      "20389/20389 [==============================] - 12s 597us/step - loss: 0.6709 - binary_accuracy: 0.6361 - val_loss: 0.6784 - val_binary_accuracy: 0.6374\n",
      "Epoch 3/30\n",
      "20389/20389 [==============================] - 12s 602us/step - loss: 0.6323 - binary_accuracy: 0.6512 - val_loss: 0.6883 - val_binary_accuracy: 0.6166\n",
      "Epoch 4/30\n",
      "20389/20389 [==============================] - 12s 599us/step - loss: 0.6104 - binary_accuracy: 0.6606 - val_loss: 0.6305 - val_binary_accuracy: 0.6449\n",
      "Epoch 5/30\n",
      "20389/20389 [==============================] - 12s 600us/step - loss: 0.5953 - binary_accuracy: 0.6745 - val_loss: 0.6391 - val_binary_accuracy: 0.6349\n",
      "Epoch 6/30\n",
      "20389/20389 [==============================] - 12s 595us/step - loss: 0.5856 - binary_accuracy: 0.6768 - val_loss: 0.6311 - val_binary_accuracy: 0.6560\n",
      "Epoch 7/30\n",
      "20389/20389 [==============================] - 12s 595us/step - loss: 0.5853 - binary_accuracy: 0.6781 - val_loss: 0.6593 - val_binary_accuracy: 0.6507\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.6501501501501501\n",
      "AUC is 0.7216067418770122\n",
      "F1-score is 0.5135699373695198\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_685 (Conv1D)             (None, 500, 16)      816         input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_688 (Conv1D)             (None, 500, 32)      1632        input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_761 (LeakyReLU)     (None, 500, 16)      0           conv1d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_764 (LeakyReLU)     (None, 500, 32)      0           conv1d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_609 (Dropout)           (None, 500, 16)      0           leaky_re_lu_761[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_612 (Dropout)           (None, 500, 32)      0           leaky_re_lu_764[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_691 (Conv1D)             (None, 500, 64)      3264        input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_686 (Conv1D)             (None, 500, 16)      12816       dropout_609[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_689 (Conv1D)             (None, 500, 32)      51232       dropout_612[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_767 (LeakyReLU)     (None, 500, 64)      0           conv1d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_762 (LeakyReLU)     (None, 500, 16)      0           conv1d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_765 (LeakyReLU)     (None, 500, 32)      0           conv1d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_615 (Dropout)           (None, 500, 64)      0           leaky_re_lu_767[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_610 (Dropout)           (None, 500, 16)      0           leaky_re_lu_762[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_613 (Dropout)           (None, 500, 32)      0           leaky_re_lu_765[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_692 (Conv1D)             (None, 500, 64)      204864      dropout_615[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_687 (Conv1D)             (None, 500, 16)      12816       dropout_610[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_690 (Conv1D)             (None, 500, 32)      51232       dropout_613[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_768 (LeakyReLU)     (None, 500, 64)      0           conv1d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_763 (LeakyReLU)     (None, 500, 16)      0           conv1d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_766 (LeakyReLU)     (None, 500, 32)      0           conv1d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_693 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_768[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_611 (Dropout)           (None, 500, 16)      0           leaky_re_lu_763[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_614 (Dropout)           (None, 500, 32)      0           leaky_re_lu_766[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_769 (LeakyReLU)     (None, 500, 64)      0           conv1d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 500, 112)     0           dropout_611[0][0]                \n",
      "                                                                 dropout_614[0][0]                \n",
      "                                                                 leaky_re_lu_769[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 500, 112)     448         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_770 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_770[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 1904)         0           max_pooling1d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_616 (Dropout)           (None, 1904)         0           flatten_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 128)          243840      dropout_616[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 1)            129         dense_153[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20389 samples, validate on 3599 samples\n",
      "Epoch 1/30\n",
      "20389/20389 [==============================] - 31s 2ms/step - loss: 1.4535 - binary_accuracy: 0.5938 - val_loss: 0.7120 - val_binary_accuracy: 0.6160\n",
      "Epoch 2/30\n",
      "20389/20389 [==============================] - 12s 596us/step - loss: 0.6448 - binary_accuracy: 0.6459 - val_loss: 0.6696 - val_binary_accuracy: 0.6349\n",
      "Epoch 3/30\n",
      "20389/20389 [==============================] - 12s 599us/step - loss: 0.6204 - binary_accuracy: 0.6590 - val_loss: 0.6957 - val_binary_accuracy: 0.6299\n",
      "Epoch 4/30\n",
      "20389/20389 [==============================] - 12s 599us/step - loss: 0.6007 - binary_accuracy: 0.6632 - val_loss: 0.6572 - val_binary_accuracy: 0.6391\n",
      "Epoch 5/30\n",
      "20389/20389 [==============================] - 12s 605us/step - loss: 0.5978 - binary_accuracy: 0.6706 - val_loss: 0.6467 - val_binary_accuracy: 0.6388\n",
      "Epoch 6/30\n",
      "20389/20389 [==============================] - 12s 599us/step - loss: 0.5851 - binary_accuracy: 0.6791 - val_loss: 0.6455 - val_binary_accuracy: 0.6424\n",
      "Epoch 7/30\n",
      "20389/20389 [==============================] - 12s 606us/step - loss: 0.5814 - binary_accuracy: 0.6825 - val_loss: 0.6764 - val_binary_accuracy: 0.6299\n",
      "Epoch 8/30\n",
      "20389/20389 [==============================] - 12s 602us/step - loss: 0.5774 - binary_accuracy: 0.6856 - val_loss: 0.6598 - val_binary_accuracy: 0.6460\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6599099099099099\n",
      "AUC is 0.7173028884740597\n",
      "F1-score is 0.5793871866295264\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_78 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_694 (Conv1D)             (None, 500, 16)      816         input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_697 (Conv1D)             (None, 500, 32)      1632        input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_771 (LeakyReLU)     (None, 500, 16)      0           conv1d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_774 (LeakyReLU)     (None, 500, 32)      0           conv1d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_617 (Dropout)           (None, 500, 16)      0           leaky_re_lu_771[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_620 (Dropout)           (None, 500, 32)      0           leaky_re_lu_774[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_700 (Conv1D)             (None, 500, 64)      3264        input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_695 (Conv1D)             (None, 500, 16)      12816       dropout_617[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_698 (Conv1D)             (None, 500, 32)      51232       dropout_620[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_777 (LeakyReLU)     (None, 500, 64)      0           conv1d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_772 (LeakyReLU)     (None, 500, 16)      0           conv1d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_775 (LeakyReLU)     (None, 500, 32)      0           conv1d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_623 (Dropout)           (None, 500, 64)      0           leaky_re_lu_777[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_618 (Dropout)           (None, 500, 16)      0           leaky_re_lu_772[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_621 (Dropout)           (None, 500, 32)      0           leaky_re_lu_775[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_701 (Conv1D)             (None, 500, 64)      204864      dropout_623[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_696 (Conv1D)             (None, 500, 16)      12816       dropout_618[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_699 (Conv1D)             (None, 500, 32)      51232       dropout_621[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_778 (LeakyReLU)     (None, 500, 64)      0           conv1d_701[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_773 (LeakyReLU)     (None, 500, 16)      0           conv1d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_776 (LeakyReLU)     (None, 500, 32)      0           conv1d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_702 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_778[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_619 (Dropout)           (None, 500, 16)      0           leaky_re_lu_773[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_622 (Dropout)           (None, 500, 32)      0           leaky_re_lu_776[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_779 (LeakyReLU)     (None, 500, 64)      0           conv1d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 500, 112)     0           dropout_619[0][0]                \n",
      "                                                                 dropout_622[0][0]                \n",
      "                                                                 leaky_re_lu_779[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 500, 112)     448         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_780 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_780[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)            (None, 1904)         0           max_pooling1d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_624 (Dropout)           (None, 1904)         0           flatten_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 128)          243840      dropout_624[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 1)            129         dense_155[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20389 samples, validate on 3599 samples\n",
      "Epoch 1/30\n",
      "20389/20389 [==============================] - 31s 2ms/step - loss: 1.7404 - binary_accuracy: 0.5712 - val_loss: 0.6830 - val_binary_accuracy: 0.6518\n",
      "Epoch 2/30\n",
      "20389/20389 [==============================] - 12s 602us/step - loss: 0.6545 - binary_accuracy: 0.6373 - val_loss: 0.6754 - val_binary_accuracy: 0.6224\n",
      "Epoch 3/30\n",
      "20389/20389 [==============================] - 12s 600us/step - loss: 0.6320 - binary_accuracy: 0.6488 - val_loss: 0.6555 - val_binary_accuracy: 0.6410\n",
      "Epoch 4/30\n",
      "20389/20389 [==============================] - 12s 600us/step - loss: 0.6121 - binary_accuracy: 0.6581 - val_loss: 0.7218 - val_binary_accuracy: 0.6177\n",
      "Epoch 5/30\n",
      "20389/20389 [==============================] - 12s 605us/step - loss: 0.6008 - binary_accuracy: 0.6674 - val_loss: 0.7585 - val_binary_accuracy: 0.6085\n",
      "Epoch 6/30\n",
      "20389/20389 [==============================] - 12s 600us/step - loss: 0.5951 - binary_accuracy: 0.6703 - val_loss: 0.6676 - val_binary_accuracy: 0.6149\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6546546546546547\n",
      "AUC is 0.7159986563139716\n",
      "F1-score is 0.6551724137931034\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_703 (Conv1D)             (None, 500, 16)      816         input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_706 (Conv1D)             (None, 500, 32)      1632        input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_781 (LeakyReLU)     (None, 500, 16)      0           conv1d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_784 (LeakyReLU)     (None, 500, 32)      0           conv1d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_625 (Dropout)           (None, 500, 16)      0           leaky_re_lu_781[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_628 (Dropout)           (None, 500, 32)      0           leaky_re_lu_784[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_709 (Conv1D)             (None, 500, 64)      3264        input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_704 (Conv1D)             (None, 500, 16)      12816       dropout_625[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_707 (Conv1D)             (None, 500, 32)      51232       dropout_628[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_787 (LeakyReLU)     (None, 500, 64)      0           conv1d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_782 (LeakyReLU)     (None, 500, 16)      0           conv1d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_785 (LeakyReLU)     (None, 500, 32)      0           conv1d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_631 (Dropout)           (None, 500, 64)      0           leaky_re_lu_787[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_626 (Dropout)           (None, 500, 16)      0           leaky_re_lu_782[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_629 (Dropout)           (None, 500, 32)      0           leaky_re_lu_785[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_710 (Conv1D)             (None, 500, 64)      204864      dropout_631[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_705 (Conv1D)             (None, 500, 16)      12816       dropout_626[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_708 (Conv1D)             (None, 500, 32)      51232       dropout_629[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_788 (LeakyReLU)     (None, 500, 64)      0           conv1d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_783 (LeakyReLU)     (None, 500, 16)      0           conv1d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_786 (LeakyReLU)     (None, 500, 32)      0           conv1d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_711 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_788[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_627 (Dropout)           (None, 500, 16)      0           leaky_re_lu_783[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_630 (Dropout)           (None, 500, 32)      0           leaky_re_lu_786[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_789 (LeakyReLU)     (None, 500, 64)      0           conv1d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 500, 112)     0           dropout_627[0][0]                \n",
      "                                                                 dropout_630[0][0]                \n",
      "                                                                 leaky_re_lu_789[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 500, 112)     448         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_790 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_790[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 1904)         0           max_pooling1d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_632 (Dropout)           (None, 1904)         0           flatten_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 128)          243840      dropout_632[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 1)            129         dense_157[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20389 samples, validate on 3599 samples\n",
      "Epoch 1/30\n",
      "20389/20389 [==============================] - 32s 2ms/step - loss: 1.7161 - binary_accuracy: 0.5908 - val_loss: 0.7266 - val_binary_accuracy: 0.6060\n",
      "Epoch 2/30\n",
      " 8768/20389 [===========>..................] - ETA: 6s - loss: 0.6975 - binary_accuracy: 0.6332"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "    extend_x = np.flip(X_train, axis=1)\n",
    "    extend_y = Y_train\n",
    "\n",
    "    X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "    Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    print('Build model...')\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Dropout(dropout)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "    middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "    middle = BatchNorm()(middle)\n",
    "    middle = LeakyReLU(alpha=0.01)(middle)\n",
    "    middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "    middle = Flatten()(middle)\n",
    "    middle = Dropout(dropout)(middle)\n",
    "\n",
    "    out = Dense(128, activation='linear')(middle)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation - dilated Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_62 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_550 (Conv1D)             (None, 500, 16)      816         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_553 (Conv1D)             (None, 500, 32)      1632        input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_611 (LeakyReLU)     (None, 500, 16)      0           conv1d_550[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_614 (LeakyReLU)     (None, 500, 32)      0           conv1d_553[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_489 (Dropout)           (None, 500, 16)      0           leaky_re_lu_611[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_492 (Dropout)           (None, 500, 32)      0           leaky_re_lu_614[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_556 (Conv1D)             (None, 500, 64)      3264        input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_551 (Conv1D)             (None, 500, 16)      12816       dropout_489[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_554 (Conv1D)             (None, 500, 32)      51232       dropout_492[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_617 (LeakyReLU)     (None, 500, 64)      0           conv1d_556[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_612 (LeakyReLU)     (None, 500, 16)      0           conv1d_551[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_615 (LeakyReLU)     (None, 500, 32)      0           conv1d_554[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_495 (Dropout)           (None, 500, 64)      0           leaky_re_lu_617[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_490 (Dropout)           (None, 500, 16)      0           leaky_re_lu_612[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_493 (Dropout)           (None, 500, 32)      0           leaky_re_lu_615[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_557 (Conv1D)             (None, 500, 64)      204864      dropout_495[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_552 (Conv1D)             (None, 500, 16)      12816       dropout_490[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_555 (Conv1D)             (None, 500, 32)      51232       dropout_493[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_618 (LeakyReLU)     (None, 500, 64)      0           conv1d_557[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_613 (LeakyReLU)     (None, 500, 16)      0           conv1d_552[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_616 (LeakyReLU)     (None, 500, 32)      0           conv1d_555[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_558 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_618[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_491 (Dropout)           (None, 500, 16)      0           leaky_re_lu_613[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_494 (Dropout)           (None, 500, 32)      0           leaky_re_lu_616[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_619 (LeakyReLU)     (None, 500, 64)      0           conv1d_558[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 500, 112)     0           dropout_491[0][0]                \n",
      "                                                                 dropout_494[0][0]                \n",
      "                                                                 leaky_re_lu_619[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 500, 112)     448         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_620 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_620[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_62 (Flatten)            (None, 1904)         0           max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_496 (Dropout)           (None, 1904)         0           flatten_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 128)          243840      dropout_496[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 1)            129         dense_123[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11325/11325 [==============================] - 21s 2ms/step - loss: 1.7766 - binary_accuracy: 0.5533 - val_loss: 0.8751 - val_binary_accuracy: 0.3612\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 6s 570us/step - loss: 0.7209 - binary_accuracy: 0.6205 - val_loss: 0.9394 - val_binary_accuracy: 0.6398\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.6414 - binary_accuracy: 0.6475 - val_loss: 0.7491 - val_binary_accuracy: 0.4902\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.6365 - binary_accuracy: 0.6565 - val_loss: 0.9351 - val_binary_accuracy: 0.5633\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 7s 575us/step - loss: 0.6050 - binary_accuracy: 0.6755 - val_loss: 0.6802 - val_binary_accuracy: 0.5843\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 6s 573us/step - loss: 0.5923 - binary_accuracy: 0.6783 - val_loss: 0.7595 - val_binary_accuracy: 0.4707\n",
      "Epoch 7/30\n",
      "11325/11325 [==============================] - 7s 576us/step - loss: 0.5807 - binary_accuracy: 0.6859 - val_loss: 0.7744 - val_binary_accuracy: 0.5693\n",
      "Epoch 8/30\n",
      "11325/11325 [==============================] - 7s 582us/step - loss: 0.5748 - binary_accuracy: 0.6869 - val_loss: 0.7830 - val_binary_accuracy: 0.5848\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6167341430499326\n",
      "AUC is 0.6689541251655038\n",
      "F1-score is 0.4453125\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_559 (Conv1D)             (None, 500, 16)      816         input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_562 (Conv1D)             (None, 500, 32)      1632        input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_621 (LeakyReLU)     (None, 500, 16)      0           conv1d_559[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_624 (LeakyReLU)     (None, 500, 32)      0           conv1d_562[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_497 (Dropout)           (None, 500, 16)      0           leaky_re_lu_621[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_500 (Dropout)           (None, 500, 32)      0           leaky_re_lu_624[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_565 (Conv1D)             (None, 500, 64)      3264        input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_560 (Conv1D)             (None, 500, 16)      12816       dropout_497[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_563 (Conv1D)             (None, 500, 32)      51232       dropout_500[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_627 (LeakyReLU)     (None, 500, 64)      0           conv1d_565[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_622 (LeakyReLU)     (None, 500, 16)      0           conv1d_560[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_625 (LeakyReLU)     (None, 500, 32)      0           conv1d_563[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_503 (Dropout)           (None, 500, 64)      0           leaky_re_lu_627[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_498 (Dropout)           (None, 500, 16)      0           leaky_re_lu_622[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_501 (Dropout)           (None, 500, 32)      0           leaky_re_lu_625[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_566 (Conv1D)             (None, 500, 64)      204864      dropout_503[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_561 (Conv1D)             (None, 500, 16)      12816       dropout_498[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_564 (Conv1D)             (None, 500, 32)      51232       dropout_501[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_628 (LeakyReLU)     (None, 500, 64)      0           conv1d_566[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_623 (LeakyReLU)     (None, 500, 16)      0           conv1d_561[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_626 (LeakyReLU)     (None, 500, 32)      0           conv1d_564[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_567 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_628[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_499 (Dropout)           (None, 500, 16)      0           leaky_re_lu_623[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_502 (Dropout)           (None, 500, 32)      0           leaky_re_lu_626[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_629 (LeakyReLU)     (None, 500, 64)      0           conv1d_567[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 500, 112)     0           dropout_499[0][0]                \n",
      "                                                                 dropout_502[0][0]                \n",
      "                                                                 leaky_re_lu_629[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 500, 112)     448         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_630 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_630[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_63 (Flatten)            (None, 1904)         0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_504 (Dropout)           (None, 1904)         0           flatten_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 128)          243840      dropout_504[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 1)            129         dense_125[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n",
      "Train on 11325 samples, validate on 1999 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11325/11325 [==============================] - 21s 2ms/step - loss: 1.8035 - binary_accuracy: 0.5571 - val_loss: 1.1180 - val_binary_accuracy: 0.3802\n",
      "Epoch 2/30\n",
      "11325/11325 [==============================] - 7s 579us/step - loss: 0.6883 - binary_accuracy: 0.6291 - val_loss: 0.7757 - val_binary_accuracy: 0.4622\n",
      "Epoch 3/30\n",
      "11325/11325 [==============================] - 7s 578us/step - loss: 0.6337 - binary_accuracy: 0.6502 - val_loss: 0.7156 - val_binary_accuracy: 0.6078\n",
      "Epoch 4/30\n",
      "11325/11325 [==============================] - 7s 578us/step - loss: 0.6073 - binary_accuracy: 0.6650 - val_loss: 0.7563 - val_binary_accuracy: 0.4887\n",
      "Epoch 5/30\n",
      "11325/11325 [==============================] - 7s 579us/step - loss: 0.6100 - binary_accuracy: 0.6695 - val_loss: 0.7454 - val_binary_accuracy: 0.5033\n",
      "Epoch 6/30\n",
      "11325/11325 [==============================] - 7s 577us/step - loss: 0.5841 - binary_accuracy: 0.6834 - val_loss: 0.7793 - val_binary_accuracy: 0.5893\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.5391363022941971\n",
      "AUC is 0.5953511412705957\n",
      "F1-score is 0.18593563766388557\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_64 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_568 (Conv1D)             (None, 500, 16)      816         input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_571 (Conv1D)             (None, 500, 32)      1632        input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_631 (LeakyReLU)     (None, 500, 16)      0           conv1d_568[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_634 (LeakyReLU)     (None, 500, 32)      0           conv1d_571[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_505 (Dropout)           (None, 500, 16)      0           leaky_re_lu_631[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_508 (Dropout)           (None, 500, 32)      0           leaky_re_lu_634[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_574 (Conv1D)             (None, 500, 64)      3264        input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_569 (Conv1D)             (None, 500, 16)      12816       dropout_505[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_572 (Conv1D)             (None, 500, 32)      51232       dropout_508[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_637 (LeakyReLU)     (None, 500, 64)      0           conv1d_574[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_632 (LeakyReLU)     (None, 500, 16)      0           conv1d_569[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_635 (LeakyReLU)     (None, 500, 32)      0           conv1d_572[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_511 (Dropout)           (None, 500, 64)      0           leaky_re_lu_637[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_506 (Dropout)           (None, 500, 16)      0           leaky_re_lu_632[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_509 (Dropout)           (None, 500, 32)      0           leaky_re_lu_635[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_575 (Conv1D)             (None, 500, 64)      204864      dropout_511[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_570 (Conv1D)             (None, 500, 16)      12816       dropout_506[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_573 (Conv1D)             (None, 500, 32)      51232       dropout_509[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_638 (LeakyReLU)     (None, 500, 64)      0           conv1d_575[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_633 (LeakyReLU)     (None, 500, 16)      0           conv1d_570[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_636 (LeakyReLU)     (None, 500, 32)      0           conv1d_573[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_576 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_638[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_507 (Dropout)           (None, 500, 16)      0           leaky_re_lu_633[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_510 (Dropout)           (None, 500, 32)      0           leaky_re_lu_636[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_639 (LeakyReLU)     (None, 500, 64)      0           conv1d_576[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 500, 112)     0           dropout_507[0][0]                \n",
      "                                                                 dropout_510[0][0]                \n",
      "                                                                 leaky_re_lu_639[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 500, 112)     448         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_640 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_640[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_64 (Flatten)            (None, 1904)         0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_512 (Dropout)           (None, 1904)         0           flatten_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 128)          243840      dropout_512[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 1)            129         dense_127[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 22s 2ms/step - loss: 1.4871 - binary_accuracy: 0.5885 - val_loss: 1.0863 - val_binary_accuracy: 0.6373\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 7s 579us/step - loss: 0.6808 - binary_accuracy: 0.6336 - val_loss: 0.7751 - val_binary_accuracy: 0.5188\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6571 - binary_accuracy: 0.6465 - val_loss: 0.7978 - val_binary_accuracy: 0.5618\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 7s 579us/step - loss: 0.6216 - binary_accuracy: 0.6617 - val_loss: 0.7329 - val_binary_accuracy: 0.4682\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 7s 581us/step - loss: 0.5887 - binary_accuracy: 0.6766 - val_loss: 0.8049 - val_binary_accuracy: 0.5568\n",
      "Epoch 6/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.5792 - binary_accuracy: 0.6847 - val_loss: 0.9173 - val_binary_accuracy: 0.5448\n",
      "Epoch 7/30\n",
      "11326/11326 [==============================] - 7s 577us/step - loss: 0.5703 - binary_accuracy: 0.6947 - val_loss: 0.7584 - val_binary_accuracy: 0.4832\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.6495611073598919\n",
      "AUC is 0.723737097421308\n",
      "F1-score is 0.6632057105775471\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_577 (Conv1D)             (None, 500, 16)      816         input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_580 (Conv1D)             (None, 500, 32)      1632        input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_641 (LeakyReLU)     (None, 500, 16)      0           conv1d_577[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_644 (LeakyReLU)     (None, 500, 32)      0           conv1d_580[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_513 (Dropout)           (None, 500, 16)      0           leaky_re_lu_641[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_516 (Dropout)           (None, 500, 32)      0           leaky_re_lu_644[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_583 (Conv1D)             (None, 500, 64)      3264        input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_578 (Conv1D)             (None, 500, 16)      12816       dropout_513[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_581 (Conv1D)             (None, 500, 32)      51232       dropout_516[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_647 (LeakyReLU)     (None, 500, 64)      0           conv1d_583[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_642 (LeakyReLU)     (None, 500, 16)      0           conv1d_578[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_645 (LeakyReLU)     (None, 500, 32)      0           conv1d_581[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_519 (Dropout)           (None, 500, 64)      0           leaky_re_lu_647[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_514 (Dropout)           (None, 500, 16)      0           leaky_re_lu_642[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_517 (Dropout)           (None, 500, 32)      0           leaky_re_lu_645[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_584 (Conv1D)             (None, 500, 64)      204864      dropout_519[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_579 (Conv1D)             (None, 500, 16)      12816       dropout_514[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_582 (Conv1D)             (None, 500, 32)      51232       dropout_517[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_648 (LeakyReLU)     (None, 500, 64)      0           conv1d_584[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_643 (LeakyReLU)     (None, 500, 16)      0           conv1d_579[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_646 (LeakyReLU)     (None, 500, 32)      0           conv1d_582[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_585 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_648[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_515 (Dropout)           (None, 500, 16)      0           leaky_re_lu_643[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_518 (Dropout)           (None, 500, 32)      0           leaky_re_lu_646[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_649 (LeakyReLU)     (None, 500, 64)      0           conv1d_585[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 500, 112)     0           dropout_515[0][0]                \n",
      "                                                                 dropout_518[0][0]                \n",
      "                                                                 leaky_re_lu_649[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 500, 112)     448         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_650 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_650[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 1904)         0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_520 (Dropout)           (None, 1904)         0           flatten_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 128)          243840      dropout_520[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1)            129         dense_129[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11326 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11326/11326 [==============================] - 22s 2ms/step - loss: 2.1902 - binary_accuracy: 0.5462 - val_loss: 0.7107 - val_binary_accuracy: 0.6193\n",
      "Epoch 2/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6934 - binary_accuracy: 0.6214 - val_loss: 0.9256 - val_binary_accuracy: 0.3442\n",
      "Epoch 3/30\n",
      "11326/11326 [==============================] - 7s 578us/step - loss: 0.6474 - binary_accuracy: 0.6413 - val_loss: 0.6609 - val_binary_accuracy: 0.5833\n",
      "Epoch 4/30\n",
      "11326/11326 [==============================] - 7s 581us/step - loss: 0.6378 - binary_accuracy: 0.6535 - val_loss: 0.7566 - val_binary_accuracy: 0.5858\n",
      "Epoch 5/30\n",
      "11326/11326 [==============================] - 6s 567us/step - loss: 0.6082 - binary_accuracy: 0.6703 - val_loss: 0.7072 - val_binary_accuracy: 0.4887\n",
      "Epoch 6/30\n",
      "11326/11326 [==============================] - 6s 560us/step - loss: 0.5938 - binary_accuracy: 0.6743 - val_loss: 0.8520 - val_binary_accuracy: 0.4157\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.5408507765023632\n",
      "AUC is 0.5728106649159281\n",
      "F1-score is 0.4910179640718564\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_66 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_586 (Conv1D)             (None, 500, 16)      816         input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_589 (Conv1D)             (None, 500, 32)      1632        input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_651 (LeakyReLU)     (None, 500, 16)      0           conv1d_586[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_654 (LeakyReLU)     (None, 500, 32)      0           conv1d_589[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_521 (Dropout)           (None, 500, 16)      0           leaky_re_lu_651[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_524 (Dropout)           (None, 500, 32)      0           leaky_re_lu_654[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_592 (Conv1D)             (None, 500, 64)      3264        input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_587 (Conv1D)             (None, 500, 16)      12816       dropout_521[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_590 (Conv1D)             (None, 500, 32)      51232       dropout_524[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_657 (LeakyReLU)     (None, 500, 64)      0           conv1d_592[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_652 (LeakyReLU)     (None, 500, 16)      0           conv1d_587[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_655 (LeakyReLU)     (None, 500, 32)      0           conv1d_590[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_527 (Dropout)           (None, 500, 64)      0           leaky_re_lu_657[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_522 (Dropout)           (None, 500, 16)      0           leaky_re_lu_652[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_525 (Dropout)           (None, 500, 32)      0           leaky_re_lu_655[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_593 (Conv1D)             (None, 500, 64)      204864      dropout_527[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_588 (Conv1D)             (None, 500, 16)      12816       dropout_522[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_591 (Conv1D)             (None, 500, 32)      51232       dropout_525[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_658 (LeakyReLU)     (None, 500, 64)      0           conv1d_593[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_653 (LeakyReLU)     (None, 500, 16)      0           conv1d_588[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_656 (LeakyReLU)     (None, 500, 32)      0           conv1d_591[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_594 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_658[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_523 (Dropout)           (None, 500, 16)      0           leaky_re_lu_653[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_526 (Dropout)           (None, 500, 32)      0           leaky_re_lu_656[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_659 (LeakyReLU)     (None, 500, 64)      0           conv1d_594[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 500, 112)     0           dropout_523[0][0]                \n",
      "                                                                 dropout_526[0][0]                \n",
      "                                                                 leaky_re_lu_659[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 500, 112)     448         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_660 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_660[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_66 (Flatten)            (None, 1904)         0           max_pooling1d_66[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_528 (Dropout)           (None, 1904)         0           flatten_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 128)          243840      dropout_528[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 1)            129         dense_131[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 2.3131 - binary_accuracy: 0.5465 - val_loss: 1.0552 - val_binary_accuracy: 0.6048\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.7168 - binary_accuracy: 0.6234 - val_loss: 0.7172 - val_binary_accuracy: 0.6243\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 557us/step - loss: 0.6280 - binary_accuracy: 0.6535 - val_loss: 0.7157 - val_binary_accuracy: 0.5088\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 558us/step - loss: 0.6043 - binary_accuracy: 0.6642 - val_loss: 0.7304 - val_binary_accuracy: 0.5678\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 559us/step - loss: 0.5874 - binary_accuracy: 0.6785 - val_loss: 0.7607 - val_binary_accuracy: 0.5663\n",
      "Epoch 00005: early stopping\n",
      "Accuracy is 0.6547297297297298\n",
      "AUC is 0.7121329437545654\n",
      "F1-score is 0.6362989323843415\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_595 (Conv1D)             (None, 500, 16)      816         input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_598 (Conv1D)             (None, 500, 32)      1632        input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_661 (LeakyReLU)     (None, 500, 16)      0           conv1d_595[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_664 (LeakyReLU)     (None, 500, 32)      0           conv1d_598[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_529 (Dropout)           (None, 500, 16)      0           leaky_re_lu_661[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_532 (Dropout)           (None, 500, 32)      0           leaky_re_lu_664[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_601 (Conv1D)             (None, 500, 64)      3264        input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_596 (Conv1D)             (None, 500, 16)      12816       dropout_529[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_599 (Conv1D)             (None, 500, 32)      51232       dropout_532[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_667 (LeakyReLU)     (None, 500, 64)      0           conv1d_601[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_662 (LeakyReLU)     (None, 500, 16)      0           conv1d_596[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_665 (LeakyReLU)     (None, 500, 32)      0           conv1d_599[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_535 (Dropout)           (None, 500, 64)      0           leaky_re_lu_667[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_530 (Dropout)           (None, 500, 16)      0           leaky_re_lu_662[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_533 (Dropout)           (None, 500, 32)      0           leaky_re_lu_665[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_602 (Conv1D)             (None, 500, 64)      204864      dropout_535[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_597 (Conv1D)             (None, 500, 16)      12816       dropout_530[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_600 (Conv1D)             (None, 500, 32)      51232       dropout_533[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_668 (LeakyReLU)     (None, 500, 64)      0           conv1d_602[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_663 (LeakyReLU)     (None, 500, 16)      0           conv1d_597[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_666 (LeakyReLU)     (None, 500, 32)      0           conv1d_600[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_603 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_668[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_531 (Dropout)           (None, 500, 16)      0           leaky_re_lu_663[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_534 (Dropout)           (None, 500, 32)      0           leaky_re_lu_666[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_669 (LeakyReLU)     (None, 500, 64)      0           conv1d_603[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 500, 112)     0           dropout_531[0][0]                \n",
      "                                                                 dropout_534[0][0]                \n",
      "                                                                 leaky_re_lu_669[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 500, 112)     448         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_670 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_670[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_67 (Flatten)            (None, 1904)         0           max_pooling1d_67[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_536 (Dropout)           (None, 1904)         0           flatten_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 128)          243840      dropout_536[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 1)            129         dense_133[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 1.4421 - binary_accuracy: 0.5754 - val_loss: 0.9688 - val_binary_accuracy: 0.6333\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 559us/step - loss: 0.7007 - binary_accuracy: 0.6229 - val_loss: 0.7608 - val_binary_accuracy: 0.6453\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 561us/step - loss: 0.6829 - binary_accuracy: 0.6360 - val_loss: 0.7206 - val_binary_accuracy: 0.5728\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.6238 - binary_accuracy: 0.6554 - val_loss: 0.8904 - val_binary_accuracy: 0.5733\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.6035 - binary_accuracy: 0.6657 - val_loss: 0.6825 - val_binary_accuracy: 0.5868\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.5896 - binary_accuracy: 0.6769 - val_loss: 0.7979 - val_binary_accuracy: 0.5628\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.5921 - binary_accuracy: 0.6801 - val_loss: 0.7523 - val_binary_accuracy: 0.5593\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 6s 565us/step - loss: 0.5791 - binary_accuracy: 0.6854 - val_loss: 0.7486 - val_binary_accuracy: 0.4957\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6533783783783784\n",
      "AUC is 0.7156482834185538\n",
      "F1-score is 0.6306695464362851\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_68 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_604 (Conv1D)             (None, 500, 16)      816         input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_607 (Conv1D)             (None, 500, 32)      1632        input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_671 (LeakyReLU)     (None, 500, 16)      0           conv1d_604[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_674 (LeakyReLU)     (None, 500, 32)      0           conv1d_607[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_537 (Dropout)           (None, 500, 16)      0           leaky_re_lu_671[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_540 (Dropout)           (None, 500, 32)      0           leaky_re_lu_674[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_610 (Conv1D)             (None, 500, 64)      3264        input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_605 (Conv1D)             (None, 500, 16)      12816       dropout_537[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_608 (Conv1D)             (None, 500, 32)      51232       dropout_540[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_677 (LeakyReLU)     (None, 500, 64)      0           conv1d_610[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_672 (LeakyReLU)     (None, 500, 16)      0           conv1d_605[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_675 (LeakyReLU)     (None, 500, 32)      0           conv1d_608[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_543 (Dropout)           (None, 500, 64)      0           leaky_re_lu_677[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_538 (Dropout)           (None, 500, 16)      0           leaky_re_lu_672[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_541 (Dropout)           (None, 500, 32)      0           leaky_re_lu_675[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_611 (Conv1D)             (None, 500, 64)      204864      dropout_543[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_606 (Conv1D)             (None, 500, 16)      12816       dropout_538[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_609 (Conv1D)             (None, 500, 32)      51232       dropout_541[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_678 (LeakyReLU)     (None, 500, 64)      0           conv1d_611[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_673 (LeakyReLU)     (None, 500, 16)      0           conv1d_606[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_676 (LeakyReLU)     (None, 500, 32)      0           conv1d_609[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_612 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_678[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_539 (Dropout)           (None, 500, 16)      0           leaky_re_lu_673[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_542 (Dropout)           (None, 500, 32)      0           leaky_re_lu_676[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_679 (LeakyReLU)     (None, 500, 64)      0           conv1d_612[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 500, 112)     0           dropout_539[0][0]                \n",
      "                                                                 dropout_542[0][0]                \n",
      "                                                                 leaky_re_lu_679[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 500, 112)     448         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_680 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_680[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 1904)         0           max_pooling1d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_544 (Dropout)           (None, 1904)         0           flatten_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 128)          243840      dropout_544[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 1)            129         dense_135[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 22s 2ms/step - loss: 1.0808 - binary_accuracy: 0.5766 - val_loss: 0.9084 - val_binary_accuracy: 0.3997\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 6s 560us/step - loss: 0.6821 - binary_accuracy: 0.6225 - val_loss: 0.7271 - val_binary_accuracy: 0.6233\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 6s 562us/step - loss: 0.6388 - binary_accuracy: 0.6428 - val_loss: 0.6744 - val_binary_accuracy: 0.6098\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 6s 564us/step - loss: 0.6120 - binary_accuracy: 0.6643 - val_loss: 0.7581 - val_binary_accuracy: 0.5673\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 6s 561us/step - loss: 0.5960 - binary_accuracy: 0.6759 - val_loss: 0.8150 - val_binary_accuracy: 0.5638\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 6s 564us/step - loss: 0.5880 - binary_accuracy: 0.6819 - val_loss: 0.9612 - val_binary_accuracy: 0.4592\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6168918918918919\n",
      "AUC is 0.7080204528853178\n",
      "F1-score is 0.6834170854271358\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_613 (Conv1D)             (None, 500, 16)      816         input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_616 (Conv1D)             (None, 500, 32)      1632        input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_681 (LeakyReLU)     (None, 500, 16)      0           conv1d_613[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_684 (LeakyReLU)     (None, 500, 32)      0           conv1d_616[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_545 (Dropout)           (None, 500, 16)      0           leaky_re_lu_681[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_548 (Dropout)           (None, 500, 32)      0           leaky_re_lu_684[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_619 (Conv1D)             (None, 500, 64)      3264        input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_614 (Conv1D)             (None, 500, 16)      12816       dropout_545[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_617 (Conv1D)             (None, 500, 32)      51232       dropout_548[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_687 (LeakyReLU)     (None, 500, 64)      0           conv1d_619[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_682 (LeakyReLU)     (None, 500, 16)      0           conv1d_614[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_685 (LeakyReLU)     (None, 500, 32)      0           conv1d_617[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_551 (Dropout)           (None, 500, 64)      0           leaky_re_lu_687[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_546 (Dropout)           (None, 500, 16)      0           leaky_re_lu_682[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_549 (Dropout)           (None, 500, 32)      0           leaky_re_lu_685[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_620 (Conv1D)             (None, 500, 64)      204864      dropout_551[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_615 (Conv1D)             (None, 500, 16)      12816       dropout_546[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_618 (Conv1D)             (None, 500, 32)      51232       dropout_549[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_688 (LeakyReLU)     (None, 500, 64)      0           conv1d_620[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_683 (LeakyReLU)     (None, 500, 16)      0           conv1d_615[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_686 (LeakyReLU)     (None, 500, 32)      0           conv1d_618[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_621 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_688[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_547 (Dropout)           (None, 500, 16)      0           leaky_re_lu_683[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_550 (Dropout)           (None, 500, 32)      0           leaky_re_lu_686[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_689 (LeakyReLU)     (None, 500, 64)      0           conv1d_621[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 500, 112)     0           dropout_547[0][0]                \n",
      "                                                                 dropout_550[0][0]                \n",
      "                                                                 leaky_re_lu_689[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 500, 112)     448         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_690 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_690[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 1904)         0           max_pooling1d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_552 (Dropout)           (None, 1904)         0           flatten_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 128)          243840      dropout_552[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 1)            129         dense_137[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 23s 2ms/step - loss: 1.8006 - binary_accuracy: 0.5813 - val_loss: 0.7155 - val_binary_accuracy: 0.6608\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 586us/step - loss: 0.7423 - binary_accuracy: 0.6296 - val_loss: 1.3527 - val_binary_accuracy: 0.5463\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 591us/step - loss: 0.6335 - binary_accuracy: 0.6514 - val_loss: 0.6688 - val_binary_accuracy: 0.6183\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 589us/step - loss: 0.6194 - binary_accuracy: 0.6644 - val_loss: 0.6719 - val_binary_accuracy: 0.6278\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5916 - binary_accuracy: 0.6745 - val_loss: 0.8629 - val_binary_accuracy: 0.4762\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 590us/step - loss: 0.5852 - binary_accuracy: 0.6801 - val_loss: 0.6998 - val_binary_accuracy: 0.5863\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6682432432432432\n",
      "AUC is 0.7462353907962016\n",
      "F1-score is 0.5972108285479902\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_70 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_622 (Conv1D)             (None, 500, 16)      816         input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_625 (Conv1D)             (None, 500, 32)      1632        input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_691 (LeakyReLU)     (None, 500, 16)      0           conv1d_622[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_694 (LeakyReLU)     (None, 500, 32)      0           conv1d_625[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_553 (Dropout)           (None, 500, 16)      0           leaky_re_lu_691[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_556 (Dropout)           (None, 500, 32)      0           leaky_re_lu_694[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_628 (Conv1D)             (None, 500, 64)      3264        input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_623 (Conv1D)             (None, 500, 16)      12816       dropout_553[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_626 (Conv1D)             (None, 500, 32)      51232       dropout_556[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_697 (LeakyReLU)     (None, 500, 64)      0           conv1d_628[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_692 (LeakyReLU)     (None, 500, 16)      0           conv1d_623[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_695 (LeakyReLU)     (None, 500, 32)      0           conv1d_626[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_559 (Dropout)           (None, 500, 64)      0           leaky_re_lu_697[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_554 (Dropout)           (None, 500, 16)      0           leaky_re_lu_692[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_557 (Dropout)           (None, 500, 32)      0           leaky_re_lu_695[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_629 (Conv1D)             (None, 500, 64)      204864      dropout_559[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_624 (Conv1D)             (None, 500, 16)      12816       dropout_554[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_627 (Conv1D)             (None, 500, 32)      51232       dropout_557[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_698 (LeakyReLU)     (None, 500, 64)      0           conv1d_629[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_693 (LeakyReLU)     (None, 500, 16)      0           conv1d_624[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_696 (LeakyReLU)     (None, 500, 32)      0           conv1d_627[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_630 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_698[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_555 (Dropout)           (None, 500, 16)      0           leaky_re_lu_693[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_558 (Dropout)           (None, 500, 32)      0           leaky_re_lu_696[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_699 (LeakyReLU)     (None, 500, 64)      0           conv1d_630[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 500, 112)     0           dropout_555[0][0]                \n",
      "                                                                 dropout_558[0][0]                \n",
      "                                                                 leaky_re_lu_699[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 500, 112)     448         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_700 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_700[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 1904)         0           max_pooling1d_70[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_560 (Dropout)           (None, 1904)         0           flatten_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 128)          243840      dropout_560[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 1)            129         dense_139[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 23s 2ms/step - loss: 1.9108 - binary_accuracy: 0.5633 - val_loss: 1.0247 - val_binary_accuracy: 0.6553\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 581us/step - loss: 0.6791 - binary_accuracy: 0.6207 - val_loss: 0.7271 - val_binary_accuracy: 0.6343\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 590us/step - loss: 0.6462 - binary_accuracy: 0.6346 - val_loss: 0.6948 - val_binary_accuracy: 0.6663\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 585us/step - loss: 0.6289 - binary_accuracy: 0.6469 - val_loss: 0.7622 - val_binary_accuracy: 0.5778\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 587us/step - loss: 0.6118 - binary_accuracy: 0.6624 - val_loss: 0.7511 - val_binary_accuracy: 0.5558\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5991 - binary_accuracy: 0.6733 - val_loss: 0.7463 - val_binary_accuracy: 0.5023\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.6398648648648648\n",
      "AUC is 0.6991042731921111\n",
      "F1-score is 0.6301179736294239\n",
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           (None, 500, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_631 (Conv1D)             (None, 500, 16)      816         input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_634 (Conv1D)             (None, 500, 32)      1632        input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_701 (LeakyReLU)     (None, 500, 16)      0           conv1d_631[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_704 (LeakyReLU)     (None, 500, 32)      0           conv1d_634[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_561 (Dropout)           (None, 500, 16)      0           leaky_re_lu_701[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_564 (Dropout)           (None, 500, 32)      0           leaky_re_lu_704[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_637 (Conv1D)             (None, 500, 64)      3264        input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_632 (Conv1D)             (None, 500, 16)      12816       dropout_561[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_635 (Conv1D)             (None, 500, 32)      51232       dropout_564[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_707 (LeakyReLU)     (None, 500, 64)      0           conv1d_637[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_702 (LeakyReLU)     (None, 500, 16)      0           conv1d_632[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_705 (LeakyReLU)     (None, 500, 32)      0           conv1d_635[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_567 (Dropout)           (None, 500, 64)      0           leaky_re_lu_707[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_562 (Dropout)           (None, 500, 16)      0           leaky_re_lu_702[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_565 (Dropout)           (None, 500, 32)      0           leaky_re_lu_705[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_638 (Conv1D)             (None, 500, 64)      204864      dropout_567[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_633 (Conv1D)             (None, 500, 16)      12816       dropout_562[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_636 (Conv1D)             (None, 500, 32)      51232       dropout_565[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_708 (LeakyReLU)     (None, 500, 64)      0           conv1d_638[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_703 (LeakyReLU)     (None, 500, 16)      0           conv1d_633[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_706 (LeakyReLU)     (None, 500, 32)      0           conv1d_636[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_639 (Conv1D)             (None, 500, 64)      204864      leaky_re_lu_708[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_563 (Dropout)           (None, 500, 16)      0           leaky_re_lu_703[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_566 (Dropout)           (None, 500, 32)      0           leaky_re_lu_706[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_709 (LeakyReLU)     (None, 500, 64)      0           conv1d_639[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 500, 112)     0           dropout_563[0][0]                \n",
      "                                                                 dropout_566[0][0]                \n",
      "                                                                 leaky_re_lu_709[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 500, 112)     448         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_710 (LeakyReLU)     (None, 500, 112)     0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling1D) (None, 17, 112)      0           leaky_re_lu_710[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 1904)         0           max_pooling1d_71[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_568 (Dropout)           (None, 1904)         0           flatten_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 128)          243840      dropout_568[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 1)            129         dense_141[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 787,953\n",
      "Trainable params: 787,729\n",
      "Non-trainable params: 224\n",
      "__________________________________________________________________________________________________\n",
      "Train...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11327 samples, validate on 1999 samples\n",
      "Epoch 1/30\n",
      "11327/11327 [==============================] - 24s 2ms/step - loss: 1.9938 - binary_accuracy: 0.5679 - val_loss: 0.8683 - val_binary_accuracy: 0.6408\n",
      "Epoch 2/30\n",
      "11327/11327 [==============================] - 7s 586us/step - loss: 0.6795 - binary_accuracy: 0.6312 - val_loss: 0.8442 - val_binary_accuracy: 0.6053\n",
      "Epoch 3/30\n",
      "11327/11327 [==============================] - 7s 589us/step - loss: 0.6414 - binary_accuracy: 0.6485 - val_loss: 0.7125 - val_binary_accuracy: 0.5633\n",
      "Epoch 4/30\n",
      "11327/11327 [==============================] - 7s 587us/step - loss: 0.6142 - binary_accuracy: 0.6665 - val_loss: 0.7942 - val_binary_accuracy: 0.5123\n",
      "Epoch 5/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.6105 - binary_accuracy: 0.6673 - val_loss: 0.7004 - val_binary_accuracy: 0.4857\n",
      "Epoch 6/30\n",
      "11327/11327 [==============================] - 7s 588us/step - loss: 0.5969 - binary_accuracy: 0.6740 - val_loss: 0.7205 - val_binary_accuracy: 0.5068\n",
      "Epoch 7/30\n",
      "11327/11327 [==============================] - 7s 595us/step - loss: 0.5843 - binary_accuracy: 0.6786 - val_loss: 0.7444 - val_binary_accuracy: 0.4857\n",
      "Epoch 8/30\n",
      "11327/11327 [==============================] - 7s 591us/step - loss: 0.5790 - binary_accuracy: 0.6877 - val_loss: 0.7826 - val_binary_accuracy: 0.4762\n",
      "Epoch 00008: early stopping\n",
      "Accuracy is 0.6229729729729729\n",
      "AUC is 0.7129519722425128\n",
      "F1-score is 0.6840317100792752\n",
      "Accuracy:  62.02363410287466\n",
      "AUC:  0.6854946345062597\n",
      "f1-score:  0.564721788881774\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 64\n",
    "pool_size = 30\n",
    "strides = 30\n",
    "# hidden_units = 15\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 30\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "#     extend_x = np.flip(X_train, axis=1)\n",
    "#     extend_y = Y_train\n",
    "\n",
    "#     X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "#     Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    print('Build model...')\n",
    "\n",
    "    inp = Input(shape=input_shape)\n",
    "\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same')(inp)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=2)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "    tower_1 = Conv1D(filters=16, kernel_size=50, padding='same', dilation_rate=3)(tower_1)\n",
    "    tower_1 = LeakyReLU(alpha=0.01)(tower_1)\n",
    "    tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same')(inp)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=2)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "    tower_2 = Conv1D(filters=32, kernel_size=50, padding='same', dilation_rate=3)(tower_2)\n",
    "    tower_2 = LeakyReLU(alpha=0.01)(tower_2)\n",
    "    tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same')(inp)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Dropout(dropout)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=2)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "    tower_3 = Conv1D(filters=64, kernel_size=50, padding='same', dilation_rate=3)(tower_3)\n",
    "    tower_3 = LeakyReLU(alpha=0.01)(tower_3)\n",
    "\n",
    "    middle = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=2)\n",
    "    middle = BatchNorm()(middle)\n",
    "    middle = LeakyReLU(alpha=0.01)(middle)\n",
    "    middle = MaxPooling1D(pool_size=pool_size, strides=strides, padding='same')(middle)\n",
    "    middle = Flatten()(middle)\n",
    "    middle = Dropout(dropout)(middle)\n",
    "\n",
    "    out = Dense(128, activation='linear')(middle)\n",
    "    out = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')  # was adam (rmsprop alternative)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                        validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6689541251655038,\n",
       " 0.5953511412705957,\n",
       " 0.723737097421308,\n",
       " 0.5728106649159281,\n",
       " 0.7121329437545654,\n",
       " 0.7156482834185538,\n",
       " 0.7080204528853178,\n",
       " 0.7462353907962016,\n",
       " 0.6991042731921111,\n",
       " 0.7129519722425128]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
