{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "# from keras.layers import Dropout, Flatten, Convolution1D as Conv1D, Convolution2D as Conv2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mainfs/lyceum/ao2u17/Dissertation\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "filename = '/data_encoding_MLP_chunk200.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (85,)\n",
      "Train shape (85,)\n"
     ]
    }
   ],
   "source": [
    "# h5f = h5py.File(path + filename,'r')\n",
    "# X_train = h5f['train'][:]\n",
    "# Y_train = h5f['target'][:]\n",
    "# h5f.close()\n",
    "df = pd.read_json(path + filename)\n",
    "X_train = df['data']\n",
    "Y_train = df['target']\n",
    "\n",
    "X_train = X_train.apply(lambda x: np.array(x))\n",
    "Y_train = Y_train.apply(lambda x: np.array(x))\n",
    "\n",
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack all the data in one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def stack_arr(array):\n",
    "    global res\n",
    "    try:\n",
    "        res.shape[0]\n",
    "        res = np.concatenate((res, array), axis=0)\n",
    "    except:\n",
    "        res = array\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = np.array(0)\n",
    "tmp = X_train.apply(lambda x: stack_arr(x))\n",
    "X_train = res\n",
    "\n",
    "res = np.array(0)\n",
    "tmp = Y_train.apply(lambda x: stack_arr(x))\n",
    "Y_train = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape (1607,)\n",
      "Train shape (1607, 400)\n"
     ]
    }
   ],
   "source": [
    "print('Target shape', Y_train.shape)\n",
    "print('Train shape', X_train.shape)\n",
    "# shape is two times bigger than chunk size because I stack two features here into 1-dim array\n",
    "# hold time and between time - features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1446, 400)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.iloc[4].shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Epoch 1/60\n",
      "1446/1446 [==============================] - 2s 1ms/step - loss: 1.0506 - binary_accuracy: 0.4965\n",
      "Epoch 2/60\n",
      "1446/1446 [==============================] - 0s 201us/step - loss: 0.8798 - binary_accuracy: 0.6231\n",
      "Epoch 3/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.8324 - binary_accuracy: 0.6646\n",
      "Epoch 4/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.7839 - binary_accuracy: 0.7089\n",
      "Epoch 5/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.7386 - binary_accuracy: 0.7559\n",
      "Epoch 6/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.7000 - binary_accuracy: 0.7725\n",
      "Epoch 7/60\n",
      "1446/1446 [==============================] - 0s 203us/step - loss: 0.7054 - binary_accuracy: 0.8008\n",
      "Epoch 8/60\n",
      "1446/1446 [==============================] - 0s 201us/step - loss: 0.6658 - binary_accuracy: 0.8202\n",
      "Epoch 9/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.6521 - binary_accuracy: 0.8361\n",
      "Epoch 10/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.6230 - binary_accuracy: 0.8499\n",
      "Epoch 11/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.6123 - binary_accuracy: 0.8672\n",
      "Epoch 12/60\n",
      "1446/1446 [==============================] - 0s 203us/step - loss: 0.5947 - binary_accuracy: 0.8631\n",
      "Epoch 13/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.5596 - binary_accuracy: 0.8893\n",
      "Epoch 14/60\n",
      "1446/1446 [==============================] - 0s 201us/step - loss: 0.5562 - binary_accuracy: 0.8845\n",
      "Epoch 15/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.5313 - binary_accuracy: 0.8976\n",
      "Epoch 16/60\n",
      "1446/1446 [==============================] - 0s 204us/step - loss: 0.5174 - binary_accuracy: 0.9115\n",
      "Epoch 17/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.4999 - binary_accuracy: 0.9246\n",
      "Epoch 18/60\n",
      "1446/1446 [==============================] - 0s 192us/step - loss: 0.4890 - binary_accuracy: 0.9239\n",
      "Epoch 19/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.4744 - binary_accuracy: 0.9288\n",
      "Epoch 20/60\n",
      "1446/1446 [==============================] - 0s 198us/step - loss: 0.4608 - binary_accuracy: 0.9329\n",
      "Epoch 21/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.4477 - binary_accuracy: 0.9426\n",
      "Epoch 22/60\n",
      "1446/1446 [==============================] - 0s 201us/step - loss: 0.4372 - binary_accuracy: 0.9412\n",
      "Epoch 23/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.4246 - binary_accuracy: 0.9447\n",
      "Epoch 24/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.4177 - binary_accuracy: 0.9467\n",
      "Epoch 25/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.4133 - binary_accuracy: 0.9502\n",
      "Epoch 26/60\n",
      "1446/1446 [==============================] - 0s 198us/step - loss: 0.3945 - binary_accuracy: 0.9599\n",
      "Epoch 27/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.3869 - binary_accuracy: 0.9633\n",
      "Epoch 28/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.3846 - binary_accuracy: 0.9592\n",
      "Epoch 29/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.3730 - binary_accuracy: 0.9633\n",
      "Epoch 30/60\n",
      "1446/1446 [==============================] - 0s 202us/step - loss: 0.3634 - binary_accuracy: 0.9689\n",
      "Epoch 31/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.3596 - binary_accuracy: 0.9668\n",
      "Epoch 32/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.3509 - binary_accuracy: 0.9716\n",
      "Epoch 33/60\n",
      "1446/1446 [==============================] - 0s 200us/step - loss: 0.3430 - binary_accuracy: 0.9737\n",
      "Epoch 34/60\n",
      "1446/1446 [==============================] - 0s 201us/step - loss: 0.3351 - binary_accuracy: 0.9730\n",
      "Epoch 35/60\n",
      "1446/1446 [==============================] - 0s 204us/step - loss: 0.3171 - binary_accuracy: 0.9806\n",
      "Epoch 36/60\n",
      "1446/1446 [==============================] - 0s 199us/step - loss: 0.3262 - binary_accuracy: 0.9758\n",
      "Epoch 37/60\n",
      "1446/1446 [==============================] - 0s 198us/step - loss: 0.3279 - binary_accuracy: 0.9765\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(14)  # fix the random numbers generator state\n",
    "\n",
    "batch_size = 16\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 60\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "early_stopping = EarlyStopping(monitor='loss', min_delta=0.01, patience=3, verbose=1)\n",
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64, input_dim=400))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Dropout(dropout))\n",
    "# model.add(Dense(256))\n",
    "# model.add(LeakyReLU(alpha=0.01))\n",
    "# model.add(Activation('tanh'))\n",
    "model.add(Dropout(dropout))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n",
    "\n",
    "print(\"Train...\")\n",
    "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 510us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0921382282091223, 0.6708074534161491]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y_pred = model.predict(X_test)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.6708074534161491\n",
      "AUC is 0.7135802469135802\n",
      "F1-score is 0.6748466257668712\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict_proba(X_test)\n",
    "print('Accuracy is', accuracy_score(Y_test, np.round(Y_pred)))\n",
    "AUC = roc_auc_score(Y_test, Y_pred)\n",
    "print('AUC is', AUC)\n",
    "f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "print('F1-score is', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 872us/step - loss: 1.0066 - binary_accuracy: 0.5154 - val_loss: 1.2233 - val_binary_accuracy: 0.4898\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 228us/step - loss: 0.8559 - binary_accuracy: 0.6311 - val_loss: 1.1975 - val_binary_accuracy: 0.4949\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 225us/step - loss: 0.7877 - binary_accuracy: 0.6646 - val_loss: 1.2141 - val_binary_accuracy: 0.4898\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 223us/step - loss: 0.7403 - binary_accuracy: 0.7269 - val_loss: 1.1917 - val_binary_accuracy: 0.5000\n",
      "Epoch 5/60\n",
      "1106/1106 [==============================] - 0s 226us/step - loss: 0.7096 - binary_accuracy: 0.7333 - val_loss: 1.2306 - val_binary_accuracy: 0.4796\n",
      "Epoch 6/60\n",
      "1106/1106 [==============================] - 0s 221us/step - loss: 0.6689 - binary_accuracy: 0.7749 - val_loss: 1.2304 - val_binary_accuracy: 0.4847\n",
      "Epoch 7/60\n",
      "1106/1106 [==============================] - 0s 213us/step - loss: 0.6393 - binary_accuracy: 0.7975 - val_loss: 1.2581 - val_binary_accuracy: 0.4949\n",
      "Epoch 00007: early stopping\n",
      "Accuracy is 0.5517241379310345\n",
      "AUC is 0.6071428571428572\n",
      "F1-score is 0.5517241379310344\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 861us/step - loss: 0.9191 - binary_accuracy: 0.4955 - val_loss: 1.2029 - val_binary_accuracy: 0.5102\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 221us/step - loss: 0.7667 - binary_accuracy: 0.6392 - val_loss: 1.1712 - val_binary_accuracy: 0.5204\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 221us/step - loss: 0.6722 - binary_accuracy: 0.7043 - val_loss: 1.1205 - val_binary_accuracy: 0.5408\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 225us/step - loss: 0.6134 - binary_accuracy: 0.7514 - val_loss: 1.1886 - val_binary_accuracy: 0.5612\n",
      "Epoch 5/60\n",
      "1106/1106 [==============================] - 0s 222us/step - loss: 0.5768 - binary_accuracy: 0.7776 - val_loss: 1.1280 - val_binary_accuracy: 0.5765\n",
      "Epoch 6/60\n",
      "1106/1106 [==============================] - 0s 222us/step - loss: 0.5422 - binary_accuracy: 0.7794 - val_loss: 1.1312 - val_binary_accuracy: 0.5663\n",
      "Epoch 00006: early stopping\n",
      "Accuracy is 0.5448275862068965\n",
      "AUC is 0.574095238095238\n",
      "F1-score is 0.5975609756097562\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 887us/step - loss: 0.9795 - binary_accuracy: 0.5253 - val_loss: 1.2012 - val_binary_accuracy: 0.4643\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 221us/step - loss: 0.8108 - binary_accuracy: 0.6203 - val_loss: 1.2279 - val_binary_accuracy: 0.4898\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 222us/step - loss: 0.6799 - binary_accuracy: 0.7043 - val_loss: 1.2803 - val_binary_accuracy: 0.4694\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 221us/step - loss: 0.6385 - binary_accuracy: 0.7315 - val_loss: 1.4322 - val_binary_accuracy: 0.4898\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5724137931034483\n",
      "AUC is 0.594\n",
      "F1-score is 0.6075949367088607\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 904us/step - loss: 1.0735 - binary_accuracy: 0.5163 - val_loss: 1.2595 - val_binary_accuracy: 0.5204\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 223us/step - loss: 0.9107 - binary_accuracy: 0.6058 - val_loss: 1.2945 - val_binary_accuracy: 0.5459\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 223us/step - loss: 0.8507 - binary_accuracy: 0.6646 - val_loss: 1.3743 - val_binary_accuracy: 0.5612\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 223us/step - loss: 0.8192 - binary_accuracy: 0.7260 - val_loss: 1.3688 - val_binary_accuracy: 0.5714\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5448275862068965\n",
      "AUC is 0.5211428571428571\n",
      "F1-score is 0.5352112676056338\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 927us/step - loss: 1.0122 - binary_accuracy: 0.5443 - val_loss: 1.3751 - val_binary_accuracy: 0.4439\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 223us/step - loss: 0.8250 - binary_accuracy: 0.6230 - val_loss: 1.4698 - val_binary_accuracy: 0.4439\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 222us/step - loss: 0.7139 - binary_accuracy: 0.6700 - val_loss: 1.4891 - val_binary_accuracy: 0.4439\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 222us/step - loss: 0.6564 - binary_accuracy: 0.7116 - val_loss: 1.4708 - val_binary_accuracy: 0.4847\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5310344827586206\n",
      "AUC is 0.5348571428571429\n",
      "F1-score is 0.5526315789473684\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 946us/step - loss: 1.0328 - binary_accuracy: 0.5136 - val_loss: 1.3284 - val_binary_accuracy: 0.4490\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 226us/step - loss: 0.9190 - binary_accuracy: 0.6293 - val_loss: 1.6372 - val_binary_accuracy: 0.4541\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 226us/step - loss: 0.8522 - binary_accuracy: 0.6637 - val_loss: 1.6065 - val_binary_accuracy: 0.4643\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 225us/step - loss: 0.7210 - binary_accuracy: 0.7324 - val_loss: 1.5145 - val_binary_accuracy: 0.5153\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5448275862068965\n",
      "AUC is 0.5843809523809524\n",
      "F1-score is 0.5822784810126581\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 972us/step - loss: 0.9418 - binary_accuracy: 0.5208 - val_loss: 1.3909 - val_binary_accuracy: 0.4796\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 231us/step - loss: 0.7372 - binary_accuracy: 0.6230 - val_loss: 1.5429 - val_binary_accuracy: 0.5051\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 233us/step - loss: 0.7054 - binary_accuracy: 0.6944 - val_loss: 1.5767 - val_binary_accuracy: 0.5051\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 226us/step - loss: 0.6517 - binary_accuracy: 0.7152 - val_loss: 1.6040 - val_binary_accuracy: 0.4898\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5586206896551724\n",
      "AUC is 0.5427619047619047\n",
      "F1-score is 0.5844155844155844\n",
      "Train...\n",
      "Train on 1106 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1106/1106 [==============================] - 1s 991us/step - loss: 1.0031 - binary_accuracy: 0.5118 - val_loss: 1.1672 - val_binary_accuracy: 0.5000\n",
      "Epoch 2/60\n",
      "1106/1106 [==============================] - 0s 226us/step - loss: 0.7943 - binary_accuracy: 0.6293 - val_loss: 1.2543 - val_binary_accuracy: 0.4898\n",
      "Epoch 3/60\n",
      "1106/1106 [==============================] - 0s 228us/step - loss: 0.7588 - binary_accuracy: 0.6844 - val_loss: 1.3438 - val_binary_accuracy: 0.5051\n",
      "Epoch 4/60\n",
      "1106/1106 [==============================] - 0s 231us/step - loss: 0.6916 - binary_accuracy: 0.7342 - val_loss: 1.3419 - val_binary_accuracy: 0.5102\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5586206896551724\n",
      "AUC is 0.6150476190476191\n",
      "F1-score is 0.6144578313253011\n",
      "Train...\n",
      "Train on 1107 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1107/1107 [==============================] - 1s 1ms/step - loss: 0.9712 - binary_accuracy: 0.5059 - val_loss: 1.3088 - val_binary_accuracy: 0.4898\n",
      "Epoch 2/60\n",
      "1107/1107 [==============================] - 0s 230us/step - loss: 0.8144 - binary_accuracy: 0.6323 - val_loss: 1.3160 - val_binary_accuracy: 0.5204\n",
      "Epoch 3/60\n",
      "1107/1107 [==============================] - 0s 229us/step - loss: 0.7328 - binary_accuracy: 0.6703 - val_loss: 1.3582 - val_binary_accuracy: 0.5153\n",
      "Epoch 4/60\n",
      "1107/1107 [==============================] - 0s 226us/step - loss: 0.6871 - binary_accuracy: 0.7046 - val_loss: 1.3580 - val_binary_accuracy: 0.4643\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.5416666666666666\n",
      "AUC is 0.5926640926640926\n",
      "F1-score is 0.5657894736842106\n",
      "Train...\n",
      "Train on 1108 samples, validate on 196 samples\n",
      "Epoch 1/60\n",
      "1108/1108 [==============================] - 1s 1ms/step - loss: 1.0185 - binary_accuracy: 0.5135 - val_loss: 1.3010 - val_binary_accuracy: 0.4796\n",
      "Epoch 2/60\n",
      "1108/1108 [==============================] - 0s 229us/step - loss: 0.8438 - binary_accuracy: 0.6236 - val_loss: 1.3686 - val_binary_accuracy: 0.5051\n",
      "Epoch 3/60\n",
      "1108/1108 [==============================] - 0s 227us/step - loss: 0.7371 - binary_accuracy: 0.6823 - val_loss: 1.3898 - val_binary_accuracy: 0.5153\n",
      "Epoch 4/60\n",
      "1108/1108 [==============================] - 0s 229us/step - loss: 0.7111 - binary_accuracy: 0.7347 - val_loss: 1.4211 - val_binary_accuracy: 0.5357\n",
      "Epoch 00004: early stopping\n",
      "Accuracy is 0.6013986013986014\n",
      "AUC is 0.6108499804151977\n",
      "F1-score is 0.5957446808510638\n",
      "Accuracy:  55.499618197894065\n",
      "AUC:  0.5776942644507862\n",
      "f1-score:  0.5787408948091471\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "acc_list = []\n",
    "AUC_list = []\n",
    "f1_list = []\n",
    "loss = []\n",
    "\n",
    "batch_size = 16\n",
    "input_shape = X_train.shape[1:]\n",
    "nb_epochs = 60\n",
    "nb_classes = 1\n",
    "dropout = 0.05\n",
    "print('Build model...')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=3, verbose=1)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "for train, test in kfold.split(X, Y):\n",
    "    \n",
    "    X_train = X[train]\n",
    "    Y_train = Y[train]\n",
    "    X_test = X[test]\n",
    "    Y_test = Y[test]\n",
    "    \n",
    "    # added flip of the training data\n",
    "#     extend_x = np.flip(X_train, axis=1)\n",
    "#     extend_y = Y_train\n",
    "\n",
    "#     X_train = np.concatenate((X_train, extend_x), axis=0)\n",
    "#     Y_train = np.concatenate((Y_train, extend_y), axis=0)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(64, input_dim=400))\n",
    "    # model.add(Activation('tanh'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    # model.add(Dropout(dropout))\n",
    "    # model.add(Dense(256))\n",
    "    # model.add(LeakyReLU(alpha=0.01))\n",
    "    # model.add(Activation('tanh'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n",
    "\n",
    "    print(\"Train...\")\n",
    "    history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epochs, verbose=1, callbacks=[early_stopping],\n",
    "                       validation_split=0.15)\n",
    "\n",
    "    Y_pred = model.predict_proba(X_test)\n",
    "    acc = accuracy_score(Y_test, np.round(Y_pred))\n",
    "    print('Accuracy is', acc)\n",
    "    AUC = roc_auc_score(Y_test, Y_pred)\n",
    "    print('AUC is', AUC)\n",
    "    f1 = f1_score(Y_test, np.round(Y_pred))\n",
    "    print('F1-score is', f1)\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    AUC_list.append(AUC)\n",
    "    f1_list.append(f1)\n",
    "    loss.append(np.mean(history.history['val_loss']))\n",
    "    \n",
    "print('Accuracy: ', np.mean(acc_list)*100)\n",
    "print('AUC: ', np.mean(AUC_list))\n",
    "print('f1-score: ', np.mean(f1_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6071428571428572,\n",
       " 0.574095238095238,\n",
       " 0.594,\n",
       " 0.5211428571428571,\n",
       " 0.5348571428571429,\n",
       " 0.5843809523809524,\n",
       " 0.5427619047619047,\n",
       " 0.6150476190476191,\n",
       " 0.5926640926640926,\n",
       " 0.6108499804151977]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP cross-validation\n",
    "AUC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/lyceum/ao2u17/.conda/envs/keras_env/lib/python3.6/site-packages/matplotlib/font_manager.py:1328: UserWarning: findfont: Font family ['normal'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "# plt.scatter([1 for i in AUC_list], AUC_list)\n",
    "plt.boxplot(AUC_list)\n",
    "\n",
    "bars = ['MLP']\n",
    "y_pos = [1]\n",
    "plt.ylabel('AUC')\n",
    "plt.xticks(y_pos, bars)\n",
    "plt.grid()\n",
    "plt.ylim((0.5, 0.7))\n",
    "# plt.xlim((0.25, 0.75))\n",
    "plt.savefig('graphs/mlp_auc.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
