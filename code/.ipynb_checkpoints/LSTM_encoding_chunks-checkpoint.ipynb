{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD_MIT-CS1PD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nqDataLoader as nq  #data loading library\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground Ground Truth \n",
    "cs1PdFr = pd.read_csv( 'MIT-CS1PD/GT_DataPD_MIT-CS1PD.csv' )\n",
    "# set Patient ID as index\n",
    "cs1PdFr = cs1PdFr.set_index('pID')\n",
    "# load ground Ground Truth \n",
    "cs2PdFr = pd.read_csv( 'MIT-CS2PD/GT_DataPD_MIT-CS2PD.csv' )\n",
    "# set Patient ID as index\n",
    "cs2PdFr = cs2PdFr.set_index('pID')\n",
    "# show part of Data Frame\n",
    "# cs2PdFr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames = ['file_1', 'file_2']\n",
    "patients = pd.DataFrame(columns=['id', 'data', 'label'])\n",
    "def load_all(record):\n",
    "    global filenames, patients\n",
    "    name = record.name\n",
    "    \n",
    "    arr = np.empty(shape=(0, 0))\n",
    "    keyp = pd.Series()\n",
    "    for filename in filenames:\n",
    "        keyPressed, htArr, pressArr, releaseArr = \\\n",
    "                nq.getDataFiltHelper( 'MIT-CS1PD/data_MIT-CS1PD/' + cs1PdFr.loc[name][filename])\n",
    "        arr = np.append(arr, htArr)\n",
    "        keyp = keyp.append(pd.Series(keyPressed))\n",
    "        \n",
    "    patients = patients.append({'id': name, 'data': arr, 'key': keyp, 'label': record['gt']}, ignore_index=True)\n",
    "    return True\n",
    "\n",
    "def load_all_d2(record):\n",
    "    global patients\n",
    "    filenames = ['file_1']\n",
    "    name = record.name\n",
    "    \n",
    "    arr = np.empty(shape=(0, 0))\n",
    "    keyp = pd.Series()\n",
    "    for filename in filenames:\n",
    "        keyPressed, htArr, pressArr, releaseArr = \\\n",
    "                nq.getDataFiltHelper( 'MIT-CS2PD/data_MIT-CS2PD/' + cs2PdFr.loc[name][filename])\n",
    "        arr = np.append(arr, htArr)\n",
    "        keyp = keyp.append(pd.Series(keyPressed))\n",
    "        \n",
    "    patients = patients.append({'id': name, 'data': arr, 'key': keyp, 'label': record['gt']}, ignore_index=True)\n",
    "    return True\n",
    "\n",
    "def remove_quotes(row):    \n",
    "    return list(row.apply(lambda x: x.replace('\"', '')))\n",
    "\n",
    "    \n",
    "tmp = cs1PdFr.apply(lambda x: load_all(x), axis=1)\n",
    "tmp = cs2PdFr.apply(lambda x: load_all_d2(x), axis=1)\n",
    "\n",
    "patients.set_index('id', inplace=True)\n",
    "\n",
    "patients['key'] = patients['key'].apply(lambda x: remove_quotes(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map key to row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keyss = set()\n",
    "\n",
    "def add_to_set(row):\n",
    "    global keyss\n",
    "    keyss.update(row)\n",
    "tmp = patients['key'].apply(lambda x: add_to_set(x))\n",
    "# patients.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '6',\n",
       " '9',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'Caps_Lock',\n",
       " 'D',\n",
       " 'Delete',\n",
       " 'Down',\n",
       " 'E',\n",
       " 'End',\n",
       " 'Escape',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'Insert',\n",
       " 'J',\n",
       " 'L',\n",
       " 'Left',\n",
       " 'M',\n",
       " 'Menu',\n",
       " 'N',\n",
       " 'Num_Lock',\n",
       " 'O',\n",
       " 'P',\n",
       " 'P_Add',\n",
       " 'P_Down',\n",
       " 'P_End',\n",
       " 'P_Enter',\n",
       " 'P_Home',\n",
       " 'P_Insert',\n",
       " 'P_Left',\n",
       " 'P_Next',\n",
       " 'P_Page_Up',\n",
       " 'P_Subtract',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'Return',\n",
       " 'Right',\n",
       " 'S',\n",
       " 'Super_L',\n",
       " 'T',\n",
       " 'Tab',\n",
       " 'U',\n",
       " 'Up',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[269025200]',\n",
       " '[269025201]',\n",
       " '[65027]',\n",
       " '[65104]',\n",
       " '[65105]',\n",
       " 'a',\n",
       " 'acute',\n",
       " 'apostrophe',\n",
       " 'b',\n",
       " 'c',\n",
       " 'ccedilla',\n",
       " 'colon',\n",
       " 'comma',\n",
       " 'd',\n",
       " 'e',\n",
       " 'exclam',\n",
       " 'exclamdown',\n",
       " 'f',\n",
       " 'g',\n",
       " 'grave',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'less',\n",
       " 'm',\n",
       " 'masculine',\n",
       " 'minus',\n",
       " 'n',\n",
       " 'ntilde',\n",
       " 'o',\n",
       " 'p',\n",
       " 'parenleft',\n",
       " 'parenright',\n",
       " 'period',\n",
       " 'periodcentered',\n",
       " 'plus',\n",
       " 'q',\n",
       " 'question',\n",
       " 'quotedbl',\n",
       " 'r',\n",
       " 's',\n",
       " 'semicolon',\n",
       " 'space',\n",
       " 't',\n",
       " 'u',\n",
       " 'underscore',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cs1PdFr.iloc[0].name\n",
    "keyboard = {1: ['Escape', '[269025200]', '[269025201]', '[65027]', '[65104]', '[65105]', ''],\n",
    "            2: ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', 'masculine', 'exclam', 'exclamdown', 'question', 'apostrophe', 'Insert', 'Num_Lock', 'P_Subtract'], \n",
    "            3: ['q', 'w', 'e', 'r', 't', 'y', 'u', 'i', 'o', 'p', 'Q', 'W', 'E', 'R', 'T', 'Y', 'U', 'I', 'O', 'P', 'Tab', 'grave', 'plus', 'Delete', 'End', 'P_Add', 'P_Home', 'P_Page_Up'], \n",
    "            4: ['a', 's', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'A', 'S', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'Caps_Lock', 'ntilde', 'parenleft', 'parenright', 'acute', 'ccedilla', 'quotedbl', 'P_Left', 'Return'], \n",
    "            5: ['z', 'x', 'c', 'v', 'b', 'n', 'm', 'Z', 'X', 'C', 'V', 'B', 'N', 'M', 'less', 'colon', 'semicolon', 'period', 'periodcentered', 'comma', 'minus', 'underscore', 'Up', 'P_End', 'P_Down', 'P_Enter', 'P_Next'], \n",
    "            6: ['space', 'Super_L', 'Left', 'Menu', 'Down', 'Right', 'P_Insert']}\n",
    "\n",
    "# 1 is left, 2 is right\n",
    "leftright = {1: ['Escape', '[269025200]', '[269025201]', '[65027]', '[65104]', '[65105]', '', '1', '2', '3', '4', '5', 'masculine', \n",
    "                 'exclam', 'exclamdown', 'q', 'w', 'e', 'r', 't', 'Q', 'W', 'E', 'R', 'T', 'Tab', 'a', 's', 'd', 'f', 'g', \n",
    "                 'A', 'S', 'D', 'F', 'G', 'Caps_Lock', 'z', 'x', 'c', 'v', 'Z', 'X', 'C', 'V', 'Super_L', 'less'],\n",
    "             \n",
    "             2: ['6', '7', '8', '9', '0', 'question', 'apostrophe', 'Insert', 'Num_Lock', 'P_Subtract', 'y', 'u', 'i', 'o', 'p', \n",
    "                 'Y', 'U', 'I', 'O', 'P', 'grave', 'plus', 'Delete', 'End', 'P_Add', 'P_Home', 'P_Page_Up', 'h', 'j', 'k', 'l', \n",
    "                 'H', 'J', 'K', 'L', 'ntilde', 'parenleft', 'parenright', 'acute', 'ccedilla', 'quotedbl', 'P_Left', 'Return', \n",
    "                 'b', 'n', 'm', 'B', 'N', 'M', 'space', 'Left', 'Menu', 'Down', 'Right', 'P_Insert',\n",
    "                 'colon', 'semicolon', 'period', 'periodcentered', 'comma', 'minus', 'underscore', 'Up', 'P_End', 'P_Down', 'P_Enter', 'P_Next']}\n",
    "# patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digList(lst):\n",
    "    temp = []\n",
    "    for item in lst:\n",
    "        if type(item) is list:\n",
    "            temp.append(digList(item))\n",
    "        else:\n",
    "            temp.append(item)\n",
    "    return set(temp)\n",
    "\n",
    "invDict = {}\n",
    "for k, v in keyboard.items():\n",
    "    if type(v) is list:\n",
    "        items = digList(v)\n",
    "        for item in items:\n",
    "            invDict[item] = invDict.get(item, [])\n",
    "            invDict[item].append(k)\n",
    "    else:\n",
    "        invDict[v] = invDict.get(v, [])\n",
    "        invDict[v].append(k)\n",
    "\n",
    "keyboard_inv = invDict\n",
    "\n",
    "invDict = {}\n",
    "for k, v in leftright.items():\n",
    "    if type(v) is list:\n",
    "        items = digList(v)\n",
    "        for item in items:\n",
    "            invDict[item] = invDict.get(item, [])\n",
    "            invDict[item].append(k)\n",
    "    else:\n",
    "        invDict[v] = invDict.get(v, [])\n",
    "        invDict[v].append(k)\n",
    "\n",
    "leftright_inv = invDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def key_to_part(value):\n",
    "    return leftright_inv[value][0]\n",
    "\n",
    "def map_part(row):\n",
    "    return list(pd.Series(row).apply(lambda x: key_to_part(x)))\n",
    "\n",
    "def key_to_row(value):\n",
    "    return keyboard_inv[value][0]\n",
    "\n",
    "def map_rows(row):\n",
    "    return list(pd.Series(row).apply(lambda x: key_to_row(x)))\n",
    "\n",
    "patients['row'] = patients['key'].apply(lambda x: map_rows(x))\n",
    "patients['part'] = patients['key'].apply(lambda x: map_part(x))\n",
    "\n",
    "# patients.head()\n",
    "# keyboard.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = pd.DataFrame([patients['data'], patients['row'], patients['part']]), patients.label\n",
    "X_train = X_train.transpose()\n",
    "\n",
    "X_train['row'] = X_train['row'].apply(lambda x: np.array(x))\n",
    "X_train['part'] = X_train['part'].apply(lambda x: np.array(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4829,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6368\n",
      "('min is ', 299)\n"
     ]
    }
   ],
   "source": [
    "def find_max(df):\n",
    "     return max(df['key'].apply(lambda x: len(x)))\n",
    "    \n",
    "def find_mean(df):\n",
    "     return np.mean(df['key'].apply(lambda x: len(x)))\n",
    "    \n",
    "def find_min(df):\n",
    "     return min(df['key'].apply(lambda x: len(x)))\n",
    "    \n",
    "maxlen = find_max(patients)\n",
    "print(maxlen)\n",
    "print('min is ', find_min(patients))\n",
    "\n",
    "# def pad_series(series):\n",
    "#     global maxlen\n",
    "# #     if isinstance(series, np.ndarray):\n",
    "# #         series = pd.Series(series)\n",
    "# #     elif isinstance(series, list):\n",
    "# #         series = pd.Series(series)\n",
    "        \n",
    "#     diff = maxlen - series.shape[0]\n",
    "#     list_of_zeros = [0 for i in range(diff)] \n",
    "# #     return list(series.append(pd.Series(list_of_zeros)))\n",
    "#     return np.array(series.append(pd.Series(list_of_zeros)))\n",
    "\n",
    "# X_train['data'] = X_train['data'].apply(lambda x: pad_series(pd.Series(x)))\n",
    "# X_train['row'] = X_train['row'].apply(lambda x: pad_series(pd.Series(x)))\n",
    "# X_train['part'] = X_train['part'].apply(lambda x: pad_series(pd.Series(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk each time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>row</th>\n",
       "      <th>part</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1713, 0.1432, 0.0655, 0.1188, 0.0737, 0.065...</td>\n",
       "      <td>[4, 5, 3, 4, 6, 3, 5, 4, 6, 5, 3, 4, 6, 3, 3, ...</td>\n",
       "      <td>[1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[0.0895, 0.0954, 0.1738, 0.1078, 0.166, 0.1361...</td>\n",
       "      <td>[4, 3, 4, 6, 3, 5, 4, 4, 4, 3, 6, 4, 3, 6, 3, ...</td>\n",
       "      <td>[1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[0.1119, 0.1345, 0.3396, 0.1883, 0.1592, 0.134...</td>\n",
       "      <td>[4, 3, 3, 6, 3, 3, 5, 3, 4, 3, 4, 3, 6, 4, 3, ...</td>\n",
       "      <td>[1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[0.1194, 0.1337, 0.1847, 0.1499, 0.2137, 0.164...</td>\n",
       "      <td>[5, 3, 3, 3, 3, 5, 6, 3, 3, 3, 6, 5, 3, 3, 6, ...</td>\n",
       "      <td>[2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[0.1528, 0.208, 0.2084, 0.1539, 0.177, 0.2055,...</td>\n",
       "      <td>[5, 4, 4, 6, 3, 4, 4, 4, 3, 3, 4, 6, 3, 3, 3, ...</td>\n",
       "      <td>[2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data  \\\n",
       "id                                                      \n",
       "11  [0.1713, 0.1432, 0.0655, 0.1188, 0.0737, 0.065...   \n",
       "60  [0.0895, 0.0954, 0.1738, 0.1078, 0.166, 0.1361...   \n",
       "67  [0.1119, 0.1345, 0.3396, 0.1883, 0.1592, 0.134...   \n",
       "68  [0.1194, 0.1337, 0.1847, 0.1499, 0.2137, 0.164...   \n",
       "70  [0.1528, 0.208, 0.2084, 0.1539, 0.177, 0.2055,...   \n",
       "\n",
       "                                                  row  \\\n",
       "id                                                      \n",
       "11  [4, 5, 3, 4, 6, 3, 5, 4, 6, 5, 3, 4, 6, 3, 3, ...   \n",
       "60  [4, 3, 4, 6, 3, 5, 4, 4, 4, 3, 6, 4, 3, 6, 3, ...   \n",
       "67  [4, 3, 3, 6, 3, 3, 5, 3, 4, 3, 4, 3, 6, 4, 3, ...   \n",
       "68  [5, 3, 3, 3, 3, 5, 6, 3, 3, 3, 6, 5, 3, 3, 6, ...   \n",
       "70  [5, 4, 4, 6, 3, 4, 4, 4, 3, 3, 4, 6, 3, 3, 3, ...   \n",
       "\n",
       "                                                 part  target  \n",
       "id                                                             \n",
       "11  [1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, ...       1  \n",
       "60  [1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, ...       0  \n",
       "67  [1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, ...       1  \n",
       "68  [2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, ...       0  \n",
       "70  [2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, ...       1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['target'] = Y_train.astype(int)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chunk_one_patient(series, size, overlap):\n",
    "#     row = chunk_array(series['row'], size, overlap)\n",
    "#     part = chunk_array(series['part'], size, overlap)\n",
    "#     data = chunk_array(series['data'], size, overlap)\n",
    "#     target = [series['target'] for i in range(len(row))]\n",
    "    \n",
    "#     res = pd.DataFrame([data, part, row, target])\n",
    "#     res = res.transpose()\n",
    "#     return res.rename(columns={0: \"data\", 1: \"part\", 2: 'row', 3: 'target'})\n",
    "\n",
    "# def chunk_array(array, size, overlap):\n",
    "#     gen = gen_split_overlap(array, size, overlap)\n",
    "    \n",
    "#     result = []\n",
    "#     for arr in gen:\n",
    "#         # if it's the last arr add zeros (if it's 0.7 of size)\n",
    "#         if arr.shape[0] != size:\n",
    "#             if np.float(arr.shape[0]) / np.float(size) >= 0.7:\n",
    "#                 arr = np.concatenate((arr, np.zeros((size - arr.shape[0],))))\n",
    "#             else:\n",
    "#                 continue\n",
    "        \n",
    "#         result.append(arr)\n",
    "# #         print(arr.shape)\n",
    "#     return result\n",
    "    \n",
    "\n",
    "# def gen_split_overlap(seq, size, overlap):\n",
    "#     if size < 1 or overlap < 0:\n",
    "#         raise ValueError('size must be >= 1 and overlap >= 0')\n",
    "\n",
    "#     for i in range(0, len(seq) - overlap, size - overlap):            \n",
    "#         yield seq[i: i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_one_patient(series, size, overlap):\n",
    "    row = np.array(chunk_array(series['row'], size, overlap))\n",
    "    part = np.array(chunk_array(series['part'], size, overlap))\n",
    "    data = np.array(chunk_array(series['data'], size, overlap))\n",
    "    target = np.array([series['target'] for i in range(len(row))])\n",
    "    \n",
    "    cor = np.stack([data, part, row], axis=0)\n",
    "    arr = cor.reshape((cor.shape[1], cor.shape[2], cor.shape[0]))\n",
    "#     res = pd.DataFrame([arr, target])\n",
    "#     res = res.transpose()\n",
    "#     return res.rename(columns={0: \"data\", 1: 'target'})\n",
    "    return [arr, target]\n",
    "\n",
    "def chunk_array(array, size, overlap):\n",
    "    gen = gen_split_overlap(array, size, overlap)\n",
    "    \n",
    "    result = []\n",
    "    for arr in gen:\n",
    "        # if it's the last arr add zeros (if it's 0.7 of size)\n",
    "        if arr.shape[0] != size:\n",
    "            if np.float(arr.shape[0]) / np.float(size) >= 0.7:\n",
    "                arr = np.concatenate((arr, np.zeros((size - arr.shape[0],))))\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        result.append(arr)\n",
    "#         print(arr.shape)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def gen_split_overlap(seq, size, overlap):\n",
    "    if size < 1 or overlap < 0:\n",
    "        raise ValueError('size must be >= 1 and overlap >= 0')\n",
    "\n",
    "    for i in range(0, len(seq) - overlap, size - overlap):            \n",
    "        yield seq[i: i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunk_size = 20  # number of data points in one chunk\n",
    "overlap = 0.5     # overlapping between chunks in percents of chunk_size\n",
    "overlap = int(overlap*chunk_size)\n",
    "\n",
    "# one_patient = chunk_one_patient(X_train.iloc[0], chunk_size, overlap)\n",
    "# one_patient = one_patient.transpose()\n",
    "# one_patient.rename(columns={0: \"data\", 1: \"part\", 2: 'row', 3: 'target'})\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "res_df['data'] = X_train.apply(lambda x: chunk_one_patient(x, chunk_size, overlap), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_column_target(row):\n",
    "#     print(row.shape)\n",
    "    return row[1]\n",
    "\n",
    "def split_column_data(row):\n",
    "#     print(row.shape)\n",
    "    return row[0]\n",
    "\n",
    "res_df['target'] = res_df['data'].apply(lambda x: split_column_target(x))\n",
    "res_df['data'] = res_df['data'].apply(lambda x: split_column_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[[[0.1713, 0.1432, 0.0655], [0.1188, 0.0737, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[[[0.0895, 0.0954, 0.1738], [0.1078, 0.166, 0....</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[[[0.1119, 0.1345, 0.3396], [0.1883, 0.1592, 0...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[[[0.1194, 0.1337, 0.1847], [0.1499, 0.2137, 0...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[[[0.1528, 0.208, 0.2084], [0.1539, 0.177, 0.2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data  \\\n",
       "id                                                      \n",
       "11  [[[0.1713, 0.1432, 0.0655], [0.1188, 0.0737, 0...   \n",
       "60  [[[0.0895, 0.0954, 0.1738], [0.1078, 0.166, 0....   \n",
       "67  [[[0.1119, 0.1345, 0.3396], [0.1883, 0.1592, 0...   \n",
       "68  [[[0.1194, 0.1337, 0.1847], [0.1499, 0.2137, 0...   \n",
       "70  [[[0.1528, 0.208, 0.2084], [0.1539, 0.177, 0.2...   \n",
       "\n",
       "                                               target  \n",
       "id                                                     \n",
       "11  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "60  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "67  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "68  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "70  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('X_train shape', (16723, 20, 3))\n",
      "('Y_train shape', (16723,))\n"
     ]
    }
   ],
   "source": [
    "# Concatenate rows all together\n",
    "train_set = np.array((0, 0, 0))\n",
    "target_set = np.array(0)\n",
    "\n",
    "def concat_train(row):\n",
    "    global train_set\n",
    "    try: \n",
    "        train_set.shape[0]\n",
    "        train_set = np.concatenate([train_set, row])\n",
    "    except:\n",
    "        train_set = row\n",
    "\n",
    "def concat_target(row):\n",
    "    global target_set\n",
    "    try: \n",
    "        target_set.shape[0]\n",
    "        target_set = np.concatenate([target_set, row])\n",
    "    except:\n",
    "        target_set = row\n",
    "        \n",
    "tmp = res_df['data'].apply(lambda x: concat_train(x))\n",
    "tmp = res_df['target'].apply(lambda x: concat_target(x))\n",
    "\n",
    "\n",
    "print('X_train shape', train_set.shape)\n",
    "print('Y_train shape', target_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training and testing instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.1, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('encoding_LSTM_chunks20.h5', 'w')\n",
    "h5f.create_dataset('train', data=train_set)\n",
    "h5f.create_dataset('target', data=target_set)\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
