{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD_MIT-CS1PD dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nqDataLoader as nq  #data loading library\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground Ground Truth \n",
    "cs1PdFr = pd.read_csv( 'MIT-CS1PD/GT_DataPD_MIT-CS1PD.csv' )\n",
    "# set Patient ID as index\n",
    "cs1PdFr = cs1PdFr.set_index('pID')\n",
    "# load ground Ground Truth \n",
    "cs2PdFr = pd.read_csv( 'MIT-CS2PD/GT_DataPD_MIT-CS2PD.csv' )\n",
    "# set Patient ID as index\n",
    "cs2PdFr = cs2PdFr.set_index('pID')\n",
    "# show part of Data Frame\n",
    "# cs2PdFr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "nqDataLoader.py:87: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  data = np.genfromtxt(fileIn, dtype=None, delimiter=',', skip_header=0)\n"
     ]
    }
   ],
   "source": [
    "filenames = ['file_1', 'file_2']\n",
    "patients = pd.DataFrame(columns=['id', 'hold', 'label'])\n",
    "def load_all(record):\n",
    "    global filenames, patients\n",
    "    name = record.name\n",
    "    \n",
    "    arr = np.empty(shape=(0, 0))\n",
    "    arr_press = np.empty(shape=(0, 0))\n",
    "    arr_release = np.empty(shape=(0, 0))\n",
    "    keyp = pd.Series()\n",
    "    for filename in filenames:\n",
    "        keyPressed, htArr, pressArr, releaseArr = \\\n",
    "                nq.getDataFiltHelper( 'MIT-CS1PD/data_MIT-CS1PD/' + cs1PdFr.loc[name][filename])\n",
    "        arr = np.append(arr, htArr)\n",
    "        arr_press = np.append(arr_press, pressArr)\n",
    "        arr_release = np.append(arr_release, releaseArr)\n",
    "        keyp = keyp.append(pd.Series(keyPressed))\n",
    "        \n",
    "    patients = patients.append({'id': name, 'hold': arr, 'key': keyp, 'label': record['gt'], 'press': arr_press, \n",
    "                               'release': arr_release}, ignore_index=True)\n",
    "    return True\n",
    "\n",
    "def load_all_d2(record):\n",
    "    global patients\n",
    "    filenames = ['file_1']\n",
    "    name = record.name\n",
    "    \n",
    "    arr = np.empty(shape=(0, 0))\n",
    "    arr_press = np.empty(shape=(0, 0))\n",
    "    arr_release = np.empty(shape=(0, 0))\n",
    "    keyp = pd.Series()\n",
    "    for filename in filenames:\n",
    "        keyPressed, htArr, pressArr, releaseArr = \\\n",
    "                nq.getDataFiltHelper( 'MIT-CS2PD/data_MIT-CS2PD/' + cs2PdFr.loc[name][filename])\n",
    "        arr = np.append(arr, htArr)\n",
    "        arr_press = np.append(arr_press, pressArr)\n",
    "        arr_release = np.append(arr_release, releaseArr)\n",
    "        keyp = keyp.append(pd.Series(keyPressed))\n",
    "        \n",
    "    patients = patients.append({'id': name, 'hold': arr, 'key': keyp, 'label': record['gt'], 'press': arr_press, \n",
    "                               'release': arr_release}, ignore_index=True)\n",
    "    return True\n",
    "\n",
    "def remove_quotes(row):    \n",
    "    return list(row.apply(lambda x: x.replace('\"', '')))\n",
    "\n",
    "    \n",
    "tmp = cs1PdFr.apply(lambda x: load_all(x), axis=1)\n",
    "tmp = cs2PdFr.apply(lambda x: load_all_d2(x), axis=1)\n",
    "\n",
    "patients.set_index('id', inplace=True)\n",
    "\n",
    "patients['key'] = patients['key'].apply(lambda x: remove_quotes(x))\n",
    "patients = patients.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hold</th>\n",
       "      <th>label</th>\n",
       "      <th>press</th>\n",
       "      <th>release</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.1713, 0.1432, 0.0655, 0.1188, 0.0737, 0.065...</td>\n",
       "      <td>True</td>\n",
       "      <td>[2.4568, 2.7748, 2.9139, 3.0805, 3.1564, 3.435...</td>\n",
       "      <td>[2.6281, 2.918, 2.9794, 3.1992, 3.2301, 3.5004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>[0.0895, 0.0954, 0.1738, 0.1078, 0.166, 0.1361...</td>\n",
       "      <td>False</td>\n",
       "      <td>[2.6084, 2.8721, 3.9054, 5.2092, 5.893, 6.3525...</td>\n",
       "      <td>[2.6979, 2.9675, 4.0792, 5.317, 6.0589, 6.4886...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[0.1119, 0.1345, 0.3396, 0.1883, 0.1592, 0.134...</td>\n",
       "      <td>True</td>\n",
       "      <td>[1.3361, 1.9241, 2.6734, 3.1709, 3.6996, 4.082...</td>\n",
       "      <td>[1.4481, 2.0585, 3.0129, 3.3591, 3.8588, 4.217...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>[0.1194, 0.1337, 0.1847, 0.1499, 0.2137, 0.164...</td>\n",
       "      <td>False</td>\n",
       "      <td>[1.8314, 2.4218, 2.8949, 3.2413, 3.9616, 6.467...</td>\n",
       "      <td>[1.9508, 2.5555, 3.0796, 3.3912, 4.1754, 6.631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[0.1528, 0.208, 0.2084, 0.1539, 0.177, 0.2055,...</td>\n",
       "      <td>True</td>\n",
       "      <td>[0.6356, 6.0042, 6.4526, 8.0744, 9.0555, 9.484...</td>\n",
       "      <td>[0.7884, 6.2122, 6.661, 8.2283, 9.2325, 9.6897...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 hold  label  \\\n",
       "id                                                             \n",
       "11  [0.1713, 0.1432, 0.0655, 0.1188, 0.0737, 0.065...   True   \n",
       "60  [0.0895, 0.0954, 0.1738, 0.1078, 0.166, 0.1361...  False   \n",
       "67  [0.1119, 0.1345, 0.3396, 0.1883, 0.1592, 0.134...   True   \n",
       "68  [0.1194, 0.1337, 0.1847, 0.1499, 0.2137, 0.164...  False   \n",
       "70  [0.1528, 0.208, 0.2084, 0.1539, 0.177, 0.2055,...   True   \n",
       "\n",
       "                                                press  \\\n",
       "id                                                      \n",
       "11  [2.4568, 2.7748, 2.9139, 3.0805, 3.1564, 3.435...   \n",
       "60  [2.6084, 2.8721, 3.9054, 5.2092, 5.893, 6.3525...   \n",
       "67  [1.3361, 1.9241, 2.6734, 3.1709, 3.6996, 4.082...   \n",
       "68  [1.8314, 2.4218, 2.8949, 3.2413, 3.9616, 6.467...   \n",
       "70  [0.6356, 6.0042, 6.4526, 8.0744, 9.0555, 9.484...   \n",
       "\n",
       "                                              release  \n",
       "id                                                     \n",
       "11  [2.6281, 2.918, 2.9794, 3.1992, 3.2301, 3.5004...  \n",
       "60  [2.6979, 2.9675, 4.0792, 5.317, 6.0589, 6.4886...  \n",
       "67  [1.4481, 2.0585, 3.0129, 3.3591, 3.8588, 4.217...  \n",
       "68  [1.9508, 2.5555, 3.0796, 3.3912, 4.1754, 6.631...  \n",
       "70  [0.7884, 6.2122, 6.661, 8.2283, 9.2325, 9.6897...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shift and subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_series(arr):\n",
    "    series = pd.Series(arr)\n",
    "    shifted = series.shift()\n",
    "    shifted[0] = 0\n",
    "#     shifted = shifted[:-1]\n",
    "    return np.array(shifted)\n",
    "\n",
    "patients['shifted_release'] = patients['release'].apply(lambda x: shift_series(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_series(record):\n",
    "#     print('Press', record['press'][:10])\n",
    "#     print('Release', record['release'][:10])\n",
    "#     print('Shifted rel', record['shifted_release'][:10])\n",
    "    return np.round(record['press'] - record['shifted_release'], decimals=4)\n",
    "\n",
    "patients['between'] = patients.apply(lambda x: subtract_series(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hold       [0.1713, 0.1432, 0.0655, 0.1188, 0.0737, 0.065...\n",
       "latency    [2.4568, 0.1467, -0.0041, 0.1011, -0.0428, 0.2...\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(patients.iloc[0][['hold', 'between']]).transpose().apply(pd.Series)\n",
    "# patients.iloc[0][['hold', 'between']]\n",
    "tmp = pd.Series()\n",
    "tmp['hold'] = patients.iloc[0]['hold']\n",
    "tmp['latency'] = patients.iloc[0]['between']\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = patients[['hold', 'between']]\n",
    "Y_train = patients['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack(X_train.iloc[0]).shape\n",
    "X_train = X_train.apply(lambda x: np.stack(x), axis=1)\n",
    "X_train = pd.DataFrame([X_train, Y_train])\n",
    "X_train = X_train.transpose()\n",
    "X_train = X_train.rename(columns={'Unnamed 0': 'data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4829)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk and concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_one_patient(series, size, overlap):\n",
    "#     print(series['data'].shape)\n",
    "    arr1 = np.array(chunk_array(series['data'][0], size, overlap))\n",
    "    arr2 = np.array(chunk_array(series['data'][1], size, overlap))\n",
    "    res = np.concatenate([arr1, arr2], axis=1)\n",
    "#     print(arr)\n",
    "    target = np.array([series['label'] for i in range(res.shape[0])])\n",
    "#     print(target)\n",
    "    return [res, target]\n",
    "\n",
    "def chunk_array(array, size, overlap):\n",
    "#     print(array.shape)\n",
    "    gen = gen_split_overlap(array, size, overlap)\n",
    "    \n",
    "    result = []\n",
    "    for arr in gen:\n",
    "        # if it's the last arr add zeros (if it's 0.7 of size)\n",
    "        if arr.shape[0] != size:\n",
    "            if np.float(arr.shape[0]) / np.float(size) >= 0.7:\n",
    "                arr = np.concatenate((arr, np.zeros((size - arr.shape[0], ))))\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        result.append(arr)\n",
    "#         print(arr.shape)\n",
    "    return result\n",
    "    \n",
    "\n",
    "def gen_split_overlap(seq, size, overlap):\n",
    "    if size < 1 or overlap < 0:\n",
    "        raise ValueError('size must be >= 1 and overlap >= 0')\n",
    "\n",
    "    for i in range(0, len(seq) - overlap, size - overlap):            \n",
    "        yield seq[i: i + size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200  # number of data points in one chunk\n",
    "overlap = 0.5    # overlapping between chunks from 0 to 1\n",
    "overlap = int(overlap*chunk_size)\n",
    "\n",
    "# one_patient = chunk_one_patient(X_train.iloc[0], chunk_size, overlap)\n",
    "# one_patient = one_patient.transpose()\n",
    "# one_patient.rename(columns={0: \"data\", 1: \"part\", 2: 'row', 3: 'target'})\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "res_df = X_train.apply(lambda x: chunk_one_patient(x, chunk_size, overlap), axis=1)\n",
    "res_df = pd.DataFrame(res_df.apply(pd.Series))\n",
    "res_df = res_df.rename(columns={0: \"data\", 1: \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 400)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train.iloc[0]['data'].shape\n",
    "res_df.iloc[4]['data'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f = h5py.File('train_enc_D.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h5f.create_group('train')\n",
    "# h5f.create_dataset('train', data=X_train)\n",
    "# h5f.create_dataset('target', data=Y_train)\n",
    "# h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_json\n",
    "res_df.to_json('data_encoding_MLP_chunk{chunk}.json'.format(chunk=chunk_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
